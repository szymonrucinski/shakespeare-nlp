{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/szymonrucinski/shakespeare-nlp/blob/main/GPT_2_Fine_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# GPT-2 Fine-Tuning Tutorial with PyTorch & Huggingface in Colab\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKGBoVwuhM4H"
      },
      "source": [
        "This is a simplified script for fine-tuning GPT2 using Hugging Face's [Transformers library](https://huggingface.co/transformers/) and PyTorch.\n",
        "\n",
        "You should understand the basics of PyTorch and how a training loop works before getting started. [This official PyTorch tutorial](https://pytorch.org/tutorials/beginner/nn_tutorial.html) serves as an excellent introduction. Familiarity with the workings of GPT2 might be useful but isn't required. The code has been written for clarity and not re-use. I'd advise refactoring it for actual projects. I've liberally taken bits from [Chris McCormick's BERT fine-tuning tutorial](https://mccormickml.com/2019/07/22/BERT-fine-tuning/), [Ian Porter's GPT2 tutorial](https://snappishproductions.com/blog/2020/03/01/chapter-9.5-text-generation-with-gpt-2-and-only-pytorch.html.html) and the [Hugging Face Language model fine-tuning script](https://huggingface.co/transformers/v2.0.0/examples.html#language-model-fine-tuning) so full credit to them. Chris' code has pretty much provided the basis for this script - you should definitely check out his [blog](https://mccormickml.com/tutorials/).\n",
        "\n",
        "I should mention what the script doesn't cover:\n",
        "\n",
        "- Using the [nlp](https://huggingface.co/nlp/) library to load in the dataset and setting up the training workflow, which looks to streamline things rather nicely.\n",
        "- [Accumulated gradients](https://medium.com/huggingface/training-larger-batches-practical-tips-on-1-gpu-multi-gpu-distributed-setups-ec88c3e51255) - this gives larger effective batch sizes than Colab allows (GPT2 is a large model, and anything more than a batch size of 2 would be enough to get a CUDA out of memory error on Colab).\n",
        "- [Freezing layers](https://github.com/huggingface/transformers/issues/1431). This is the process of only changing the parameters in selected layers, made famous by the [ULMFit](https://arxiv.org/abs/1801.06146) process.\n",
        "- [Using 'past'](https://huggingface.co/transformers/quickstart.html#using-the-past) when generating text. This takes in the previous state when generating successive items of text. I didn't need it.\n",
        "- [Tensor packing](https://snappishproductions.com/blog/2020/03/01/chapter-9.5-text-generation-with-gpt-2-and-only-pytorch.html.html). This is a neat way of fitting in as much training data in each batch. \n",
        "- [Hyperparameter search](https://discuss.huggingface.co/t/using-hyperparameter-search-in-trainer/785/10). I settled quickly on values that seemed to produce decent values, without checking if they were optimal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf3Qw77SZGbS"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "6880fd4e-5f4b-4a66-a133-7cd0a69a67ef"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 5.6MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 23.8MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 40.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 51.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=5c1776d8601ce778a0a6a7e9da324a40c917cceb39c24687d7a26e5f3dbe0383\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCCeyhuDHdOu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "0b340a2a-1876-4e9b-bc5c-8133520ebec9"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import datetime\n",
        "from google.colab import drive\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
        "torch.manual_seed(42)\n",
        "\n",
        "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "satxtOn9CzgR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "1a07f6a7-b862-471e-976c-7722ab23570a"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Aug 28 11:03:56 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfdCML6Parvv"
      },
      "source": [
        "# Create Training Set\n",
        "\n",
        "The data used to finetune the language model is a set of around 1000 DJ biographies, with the aim of generating them in the same general format and style.\n",
        "\n",
        "This data isn't public so if you want to use this script, you'll have to source your own training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EYFrNxr-TYb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2d7ca96-25ac-4e4d-c74c-bb6cf60b190b"
      },
      "source": [
        "! curl https://media.githubusercontent.com/media/szymonrucinski/shakespeare-nlp/main/Shakespeare_data.csv -o data.csv"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 9950k  100 9950k    0     0  15.7M      0 --:--:-- --:--:-- --:--:-- 15.7M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya3zsH0r-3JK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "b24d7c9c-db14-49c2-c1a5-718581d10d2c"
      },
      "source": [
        "# load into a data frame\n",
        "orig_data = pd.read_csv(\"data.csv\")  \n",
        "display(orig_data)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        Dataline            Play  PlayerLinenumber ActSceneLine  \\\n",
              "0              1        Henry IV               NaN          NaN   \n",
              "1              2        Henry IV               NaN          NaN   \n",
              "2              3        Henry IV               NaN          NaN   \n",
              "3              4        Henry IV               1.0        1.1.1   \n",
              "4              5        Henry IV               1.0        1.1.2   \n",
              "...          ...             ...               ...          ...   \n",
              "111391    111392  A Winters Tale              38.0      5.3.180   \n",
              "111392    111393  A Winters Tale              38.0      5.3.181   \n",
              "111393    111394  A Winters Tale              38.0      5.3.182   \n",
              "111394    111395  A Winters Tale              38.0      5.3.183   \n",
              "111395    111396  A Winters Tale              38.0          NaN   \n",
              "\n",
              "               Player                                         PlayerLine  \n",
              "0                 NaN                                              ACT I  \n",
              "1                 NaN                       SCENE I. London. The palace.  \n",
              "2                 NaN  Enter KING HENRY, LORD JOHN OF LANCASTER, the ...  \n",
              "3       KING HENRY IV             So shaken as we are, so wan with care,  \n",
              "4       KING HENRY IV         Find we a time for frighted peace to pant,  \n",
              "...               ...                                                ...  \n",
              "111391        LEONTES         Lead us from hence, where we may leisurely  \n",
              "111392        LEONTES              Each one demand an answer to his part  \n",
              "111393        LEONTES     Perform'd in this wide gap of time since first  \n",
              "111394        LEONTES             We were dissever'd: hastily lead away.  \n",
              "111395        LEONTES                                             Exeunt  \n",
              "\n",
              "[111396 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b8c62b55-8ac4-471d-a3a8-027d48dd0977\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataline</th>\n",
              "      <th>Play</th>\n",
              "      <th>PlayerLinenumber</th>\n",
              "      <th>ActSceneLine</th>\n",
              "      <th>Player</th>\n",
              "      <th>PlayerLine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ACT I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SCENE I. London. The palace.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Enter KING HENRY, LORD JOHN OF LANCASTER, the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.1.1</td>\n",
              "      <td>KING HENRY IV</td>\n",
              "      <td>So shaken as we are, so wan with care,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.1.2</td>\n",
              "      <td>KING HENRY IV</td>\n",
              "      <td>Find we a time for frighted peace to pant,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111391</th>\n",
              "      <td>111392</td>\n",
              "      <td>A Winters Tale</td>\n",
              "      <td>38.0</td>\n",
              "      <td>5.3.180</td>\n",
              "      <td>LEONTES</td>\n",
              "      <td>Lead us from hence, where we may leisurely</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111392</th>\n",
              "      <td>111393</td>\n",
              "      <td>A Winters Tale</td>\n",
              "      <td>38.0</td>\n",
              "      <td>5.3.181</td>\n",
              "      <td>LEONTES</td>\n",
              "      <td>Each one demand an answer to his part</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111393</th>\n",
              "      <td>111394</td>\n",
              "      <td>A Winters Tale</td>\n",
              "      <td>38.0</td>\n",
              "      <td>5.3.182</td>\n",
              "      <td>LEONTES</td>\n",
              "      <td>Perform'd in this wide gap of time since first</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111394</th>\n",
              "      <td>111395</td>\n",
              "      <td>A Winters Tale</td>\n",
              "      <td>38.0</td>\n",
              "      <td>5.3.183</td>\n",
              "      <td>LEONTES</td>\n",
              "      <td>We were dissever'd: hastily lead away.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111395</th>\n",
              "      <td>111396</td>\n",
              "      <td>A Winters Tale</td>\n",
              "      <td>38.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LEONTES</td>\n",
              "      <td>Exeunt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>111396 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8c62b55-8ac4-471d-a3a8-027d48dd0977')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b8c62b55-8ac4-471d-a3a8-027d48dd0977 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b8c62b55-8ac4-471d-a3a8-027d48dd0977');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_U3m6wr3Ahzt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "f7ca22d3-89ed-4318-ddb5-0fc04e7410d6"
      },
      "source": [
        "lines = orig_data.copy()\n",
        "lines = lines[~lines.Player.isna()][\"PlayerLine\"]\n",
        "display(lines)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "3                 So shaken as we are, so wan with care,\n",
              "4             Find we a time for frighted peace to pant,\n",
              "5         And breathe short-winded accents of new broils\n",
              "6                To be commenced in strands afar remote.\n",
              "7              No more the thirsty entrance of this soil\n",
              "                               ...                      \n",
              "111391        Lead us from hence, where we may leisurely\n",
              "111392             Each one demand an answer to his part\n",
              "111393    Perform'd in this wide gap of time since first\n",
              "111394            We were dissever'd: hastily lead away.\n",
              "111395                                            Exeunt\n",
              "Name: PlayerLine, Length: 111389, dtype: object"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ1oK0kXaV5p"
      },
      "source": [
        "We need to get an idea of how long our training documents are.\n",
        "\n",
        "I'm not going to use the same tokenizer as the GPT2 one, which is a [byte pair encoding tokenizer](https://blog.floydhub.com/tokenization-nlp/). Instead, I'm using a simple one just to get a rough understanding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKsH2sU0OCQA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "f932a278-f087-49f7-c237-5380babb966d"
      },
      "source": [
        "doc_lengths = []\n",
        "\n",
        "for l in lines:\n",
        "\n",
        "    # get rough token count distribution\n",
        "    tokens = nltk.word_tokenize(l)\n",
        "\n",
        "    doc_lengths.append(len(tokens))\n",
        "\n",
        "doc_lengths = np.array(doc_lengths)\n",
        "\n",
        "sns.distplot(doc_lengths)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7faadcf776a0>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6P6bTItJEIj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5594fd4e-93ce-456a-8bac-f82168f68d32"
      },
      "source": [
        "# the max token length   \n",
        "len(doc_lengths[doc_lengths > 768])/len(doc_lengths)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63t_69HjlwAj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ebbed2c-0a61-46ee-ee39-e58b6cca4cd7"
      },
      "source": [
        "np.average(doc_lengths)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.023736634676673"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tuq5bqdr4_a6"
      },
      "source": [
        "Even though these token counts won't match up to the BPE tokenizer's, I'm confident that most bios will be fit under the 768 embedding size limit for the small GPT2 model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMml12FJGjPW"
      },
      "source": [
        "# GPT2 Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANJhbBwdxN-b"
      },
      "source": [
        "Although the defaults take care of this,I thought I'd show that you can specify some of the special tokens. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "003f25af-167d-49c7-8d20-975241c1b1d8"
      },
      "source": [
        "# Load the GPT tokenizer.\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>') #gpt2-medium\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh0XKuDvnryn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cc54af0-62bd-4e2d-cd22-43538cd754c7"
      },
      "source": [
        "print(\"The max model length is {} for this model, although the actual embedding size for GPT small is 768\".format(tokenizer.model_max_length))\n",
        "print(\"The beginning of sequence token {} token has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.bos_token_id), tokenizer.bos_token_id))\n",
        "print(\"The end of sequence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id), tokenizer.eos_token_id))\n",
        "print(\"The padding token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.pad_token_id), tokenizer.pad_token_id))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The max model length is 1024 for this model, although the actual embedding size for GPT small is 768\n",
            "The beginning of sequence token <|startoftext|> token has the id 50257\n",
            "The end of sequence token <|endoftext|> has the id 50256\n",
            "The padding token <|pad|> has the id 50258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "# PyTorch Datasets & Dataloaders\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lgZoOYkxZfx"
      },
      "source": [
        "GPT2 is a large model. Increasing the batch size above 2 has lead to out of memory problems. This can be mitigated by accumulating the gradients but that is out of scope here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scqrzmqhV__z"
      },
      "source": [
        "batch_size = 16"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqGMee7Isfpx"
      },
      "source": [
        "I'm using the standard PyTorch approach of loading data in using a [dataset class](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html).\n",
        "\n",
        "I'm passing in the tokenizer as an argument but normally I would  instantiate it within the class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_XJVIetKN-h"
      },
      "source": [
        "class GPT2Dataset(Dataset):\n",
        "\n",
        "  def __init__(self, txt_list, tokenizer, gpt2_type=\"gpt2\", max_length=768):\n",
        "\n",
        "    self.tokenizer = tokenizer\n",
        "    self.input_ids = []\n",
        "    self.attn_masks = []\n",
        "\n",
        "    for txt in txt_list:\n",
        "\n",
        "      encodings_dict = tokenizer('<|startoftext|>'+ txt + '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\")\n",
        "\n",
        "      self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "      self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.attn_masks[idx] "
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89Z7aYUgpWrd"
      },
      "source": [
        "To understand how I've used the tokenizer, it's worth reading [the docs](https://huggingface.co/transformers/main_classes/tokenizer.html). I've wrapped each bio in the bos and eos tokens.\n",
        "\n",
        "Every tensor passed to the model should be the same length.\n",
        "\n",
        "If the bio is shorter than 768 tokens, it will be padded to a length of 768 using the padding token. In addition, an attention mask will be returned that needs to be passed to the model to tell it to ignore the padding tokens. \n",
        "\n",
        "If the bio is longer than 768 tokens, it will be truncated without the eos_token. This isn't a problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xza_O1_rD7yh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cde4c871-ae91-4d10-991d-212d86811768"
      },
      "source": [
        "dataset = GPT2Dataset(lines, tokenizer, max_length=768)\n",
        "\n",
        "# Split into training and validation sets\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100,250 training samples\n",
            "11,139 validation samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0WeP5PREUuy"
      },
      "source": [
        "# Create the DataLoaders for our training and validation datasets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6TKgyUzPIQc"
      },
      "source": [
        "# Finetune GPT2 Language Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsCTp_mporB"
      },
      "source": [
        "# I'm not really doing anything with the config buheret\n",
        "configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n",
        "\n",
        "# instantiate the model\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=configuration)\n",
        "\n",
        "# this step is necessary because I've added some tokens (bos_token, etc) to the embeddings\n",
        "# otherwise the tokenizer and model tensors won't match up\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "device = torch.device(\"cuda\")\n",
        "model.cuda()\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBEVY2PYSTXJ"
      },
      "source": [
        "# some parameters I cooked up that work reasonably well\n",
        "\n",
        "epochs = 5\n",
        "learning_rate = 5e-4\n",
        "warmup_steps = 1e2\n",
        "epsilon = 1e-8\n",
        "\n",
        "# this produces sample output every 100 steps\n",
        "sample_every = 100"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = learning_rate,\n",
        "                  eps = epsilon\n",
        "                )"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "# This changes the learning rate as the training loop progresses\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = warmup_steps, \n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCPohrZ-CTWu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "50d743d5-8822-4dc4-9511-d1359653d295"
      },
      "source": [
        "total_t0 = time.time()\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        outputs = model(  b_input_ids,\n",
        "                          labels=b_labels, \n",
        "                          attention_mask = b_masks,\n",
        "                          token_type_ids=None\n",
        "                        )\n",
        "\n",
        "        loss = outputs[0]  \n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        # Get sample every x batches.\n",
        "        if step % sample_every == 0 and not step == 0:\n",
        "\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            sample_outputs = model.generate(\n",
        "                                    bos_token_id=random.randint(1,30000),\n",
        "                                    do_sample=True,   \n",
        "                                    top_k=50, \n",
        "                                    max_length = 200,\n",
        "                                    top_p=0.95, \n",
        "                                    num_return_sequences=1\n",
        "                                )\n",
        "            for i, sample_output in enumerate(sample_outputs):\n",
        "                  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
        "            \n",
        "            model.train()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)       \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            outputs  = model(b_input_ids, \n",
        "#                            token_type_ids=None, \n",
        "                             attention_mask = b_masks,\n",
        "                            labels=b_labels)\n",
        "          \n",
        "            loss = outputs[0]  \n",
        "            \n",
        "        batch_loss = loss.item()\n",
        "        total_eval_loss += batch_loss        \n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    validation_time = format_time(time.time() - t0)    \n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-83aec538089d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         outputs = model(  b_input_ids,\n\u001b[0m\u001b[1;32m     32\u001b[0m                           \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                           \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb_masks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[1;32m   1044\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    885\u001b[0m                 )\n\u001b[1;32m    886\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m                 outputs = block(\n\u001b[0m\u001b[1;32m    888\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m                     \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m         attn_outputs = self.attn(\n\u001b[0m\u001b[1;32m    389\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upcast_and_reordered_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m             \u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36m_attn\u001b[0;34m(self, query, key, value, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_attn_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 432.00 MiB (GPU 0; 14.76 GiB total capacity; 12.88 GiB already allocated; 117.88 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "Let's view the summary of the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "995536c7-afa9-43e4-fc83-27f8d067016a"
      },
      "source": [
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.05</td>\n",
              "      <td>2.52</td>\n",
              "      <td>0:03:23</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.10</td>\n",
              "      <td>2.48</td>\n",
              "      <td>0:03:24</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.90</td>\n",
              "      <td>2.48</td>\n",
              "      <td>0:03:24</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.73</td>\n",
              "      <td>2.52</td>\n",
              "      <td>0:03:24</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.61</td>\n",
              "      <td>2.56</td>\n",
              "      <td>0:03:23</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss Training Time Validation Time\n",
              "epoch                                                          \n",
              "1               4.05         2.52       0:03:23         0:00:07\n",
              "2               2.10         2.48       0:03:24         0:00:07\n",
              "3               1.90         2.48       0:03:24         0:00:07\n",
              "4               1.73         2.52       0:03:24         0:00:07\n",
              "5               1.61         2.56       0:03:23         0:00:07"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "a4a95c98-6daf-4bf2-92e1-5ce23edcebc9"
      },
      "source": [
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuUAAAGaCAYAAACopj13AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXxM9/4/8Nes2TdZiAQhZEGQ2GqrJchirS1KbdWipbS9vW21etty+d2q0otWv8W178TWJoJYWloUraVZkJQmREQiK5JZzu+PyDAmIctMziR5PR+PPm7mcz7nnPeMczOv+eQznyMRBEEAERERERGJRip2AUREREREdR1DORERERGRyBjKiYiIiIhExlBORERERCQyhnIiIiIiIpExlBMRERERiYyhnIhqrdTUVPj6+mLZsmWVPsaHH34IX19fI1ZVe5X1evv6+uLDDz8s1zGWLVsGX19fpKamGr2+yMhI+Pr64vTp00Y/NhFRVcnFLoCI6o6KhNvY2Fh4enqasJqa5/79+/juu+8QFRWFO3fuoF69emjfvj3efPNNeHt7l+sYM2fORExMDPbs2QN/f/9S+wiCgODgYOTm5uLEiROwtLQ05tMwqdOnT+PMmTOYMGEC7O3txS7HQGpqKoKDgzF27Fj861//ErscIjIjDOVEVG0WLlyo9/jcuXPYtm0bIiIi0L59e71t9erVq/L5PDw8cPHiRchkskofY968efj888+rXIsxzJkzBz/++CMGDhyITp06ISMjA0eOHMGFCxfKHcpHjBiBmJgY7Nq1C3PmzCm1z6lTp3Dz5k1EREQYJZBfvHgRUmn1/GH2zJkzWL58OV566SWDUD5kyBAMGDAACoWiWmohIqoIhnIiqjZDhgzRe6zRaLBt2za0a9fOYNvT8vPzYWtrW6HzSSQSWFhYVLjOJ5lLgHvw4AEOHDiA7t2746uvvtK1z5gxA0VFReU+Tvfu3eHu7o79+/fj/fffh1KpNOgTGRkJoDjAG0NV/w2MRSaTVekDGhGRKXFOORGZnT59+mDcuHGIi4vD5MmT0b59ewwePBhAcThfsmQJRo4cic6dO6N169bo168fFi1ahAcPHugdp7Q5zk+2HT16FMOHD0dAQAC6d++OL774Amq1Wu8Ypc0pL2nLy8vDp59+ii5duiAgIACjR4/GhQsXDJ7PvXv3MHv2bHTu3BmBgYEYP3484uLiMG7cOPTp06dcr4lEIoFEIin1Q0JpwbosUqkUL730ErKzs3HkyBGD7fn5+Th48CB8fHzQpk2bCr3eZSltTrlWq8X//d//oU+fPggICMDAgQOxb9++UvdPSkrCZ599hgEDBiAwMBBt27bFsGHDsGPHDr1+H374IZYvXw4ACA4Ohq+vr96/f1lzyrOysvD555+jZ8+eaN26NXr27InPP/8c9+7d0+tXsv+vv/6K1atXo2/fvmjdujVCQkKwe/fucr0WFZGQkIDp06ejc+fOCAgIQHh4OFauXAmNRqPXLy0tDbNnz0bv3r3RunVrdOnSBaNHj9arSavVYu3atRg0aBACAwMRFBSEkJAQfPTRR1CpVEavnYgqjiPlRGSWbt26hQkTJiA0NBT9+/fH/fv3AQDp6enYuXMn+vfvj4EDB0Iul+PMmTNYtWoV4uPjsXr16nId//jx49i8eTNGjx6N4cOHIzY2Fv/73//g4OCAadOmlesYkydPRr169TB9+nRkZ2djzZo1mDJlCmJjY3Wj+kVFRZg0aRLi4+MxbNgwBAQEIDExEZMmTYKDg0O5Xw9LS0sMHToUu3btwg8//ICBAweWe9+nDRs2DCtWrEBkZCRCQ0P1tv344494+PAhhg8fDsB4r/fT/t//+39Yv349OnbsiIkTJyIzMxNz585Fo0aNDPqeOXMGZ8+eRa9eveDp6an7q8GcOXOQlZWFqVOnAgAiIiKQn5+PQ4cOYfbs2XBycgLw7O8y5OXl4eWXX8aNGzcwfPhwtGzZEvHx8diyZQtOnTqFHTt2GPyFZsmSJXj48CEiIiKgVCqxZcsWfPjhh2jcuLHBNKzKunTpEsaNGwe5XI6xY8fCxcUFR48exaJFi5CQkKD7a4larcakSZOQnp6OMWPGwMvLC/n5+UhMTMTZs2fx0ksvAQBWrFiBpUuXonfv3hg9ejRkMhlSU1Nx5MgRFBUVmc1fhIjqNIGISCS7du0SfHx8hF27dum19+7dW/Dx8RG2b99usE9hYaFQVFRk0L5kyRLBx8dHuHDhgq4tJSVF8PHxEZYuXWrQ1rZtWyElJUXXrtVqhQEDBgjdunXTO+4HH3wg+Pj4lNr26aef6rVHRUUJPj4+wpYtW3RtGzduFHx8fIRvv/1Wr29Je+/evQ2eS2ny8vKE119/XWjdurXQsmVL4ccffyzXfmUZP3684O/vL6Snp+u1jxo1SmjVqpWQmZkpCELVX29BEAQfHx/hgw8+0D1OSkoSfH19hfHjxwtqtVrXfvnyZcHX11fw8fHR+7cpKCgwOL9GoxFeeeUVISgoSK++pUuXGuxfouR6O3XqlK5t8eLFgo+Pj7Bx40a9viX/PkuWLDHYf8iQIUJhYaGu/fbt20KrVq2Ed955x+CcTyt5jT7//PNn9ouIiBD8/f2F+Ph4XZtWqxVmzpwp+Pj4CL/88osgCIIQHx8v+Pj4CN9///0zjzd06FAhLCzsufURkXg4fYWIzJKjoyOGDRtm0K5UKnWjemq1Gjk5OcjKykLXrl0BoNTpI6UJDg7WW91FIpGgc+fOyMjIQEFBQbmOMXHiRL3HL7zwAgDgxo0burajR49CJpNh/Pjxen1HjhwJOzu7cp1Hq9Vi1qxZSEhIQHR0NF588UW899572L9/v16/Tz75BK1atSrXHPMRI0ZAo9Fgz549urakpCT88ccf6NOnj+6LtsZ6vZ8UGxsLQRAwadIkvTnerVq1Qrdu3Qz6W1tb634uLCzEvXv3kJ2djW7duiE/Px/JyckVrqHEoUOHUK9ePUREROi1R0REoF69ejh8+LDBPmPGjNGbMlS/fn00bdoU169fr3QdT8rMzMTvv/+OPn36wM/PT9cukUjwxhtv6OoGoLuGTp8+jczMzDKPaWtri/T0dJw9e9YoNRKR8XH6ChGZpUaNGpX5pbxNmzZh69atuHbtGrRard62nJycch//aY6OjgCA7Oxs2NjYVPgYJdMlsrOzdW2pqalwc3MzOJ5SqYSnpydyc3Ofe57Y2FicOHECX375JTw9PfHf//4XM2bMwPvvvw+1Wq2bopCYmIiAgIByzTHv378/7O3tERkZiSlTpgAAdu3aBQC6qSsljPF6PyklJQUA0KxZM4Nt3t7eOHHihF5bQUEBli9fjujoaKSlpRnsU57XsCypqalo3bo15HL9t0O5XA4vLy/ExcUZ7FPWtXPz5s1K1/F0TQDQvHlzg23NmjWDVCrVvYYeHh6YNm0avv/+e3Tv3h3+/v544YUXEBoaijZt2uj2e/fddzF9+nSMHTsWbm5u6NSpE3r16oWQkJAKfSeBiEyHoZyIzJKVlVWp7WvWrMF//vMfdO/eHePHj4ebmxsUCgXS09Px4YcfQhCEch3/WatwVPUY5d2/vEq+mNixY0cAxYF++fLleOONNzB79myo1Wr4+fnhwoULmD9/frmOaWFhgYEDB2Lz5s04f/482rZti3379qFBgwbo0aOHrp+xXu+q+Mc//oFjx45h1KhR6NixIxwdHSGTyXD8+HGsXbvW4IOCqVXX8o7l9c4772DEiBE4duwYzp49i507d2L16tV47bXX8M9//hMAEBgYiEOHDuHEiRM4ffo0Tp8+jR9++AErVqzA5s2bdR9IiUg8DOVEVKPs3bsXHh4eWLlypV44+umnn0SsqmweHh749ddfUVBQoDdarlKpkJqaWq4b3JQ8z5s3b8Ld3R1AcTD/9ttvMW3aNHzyySfw8PCAj48Phg4dWu7aRowYgc2bNyMyMhI5OTnIyMjAtGnT9F5XU7zeJSPNycnJaNy4sd62pKQkvce5ubk4duwYhgwZgrlz5+pt++WXXwyOLZFIKlzLX3/9BbVarTdarlarcf369VJHxU2tZFrVtWvXDLYlJydDq9Ua1NWoUSOMGzcO48aNQ2FhISZPnoxVq1bh1VdfhbOzMwDAxsYGISEhCAkJAVD8F5C5c+di586deO2110z8rIjoeczr4z4R0XNIpVJIJBK9EVq1Wo2VK1eKWFXZ+vTpA41Gg/Xr1+u1b9++HXl5eeU6Rs+ePQEUr/rx5HxxCwsLLF68GPb29khNTUVISIjBNIxnadWqFfz9/REVFYVNmzZBIpEYrE1uite7T58+kEgkWLNmjd7yfn/++adB0C75IPD0iPydO3cMlkQEHs8/L++0mr59+yIrK8vgWNu3b0dWVhb69u1bruMYk7OzMwIDA3H06FFcuXJF1y4IAr7//nsAQL9+/QAUrx7z9JKGFhYWuqlBJa9DVlaWwXlatWql14eIxMWRciKqUUJDQ/HVV1/h9ddfR79+/ZCfn48ffvihQmG0Oo0cORJbt27F119/jb///lu3JOKBAwfQpEkTg3XRS9OtWzeMGDECO3fuxIABAzBkyBA0aNAAKSkp2Lt3L4DigPXNN9/A29sbYWFh5a5vxIgRmDdvHn7++Wd06tTJYATWFK+3t7c3xo4di40bN2LChAno378/MjMzsWnTJvj5+enN47a1tUW3bt2wb98+WFpaIiAgADdv3sS2bdvg6empN38fANq2bQsAWLRoEQYNGgQLCwu0aNECPj4+pdby2muv4cCBA5g7dy7i4uLg7++P+Ph47Ny5E02bNjXZCPLly5fx7bffGrTL5XJMmTIFH3/8McaNG4exY8dizJgxcHV1xdGjR3HixAkMHDgQXbp0AVA8temTTz5B//790bRpU9jY2ODy5cvYuXMn2rZtqwvn4eHhaNeuHdq0aQM3NzdkZGRg+/btUCgUGDBggEmeIxFVjHm+ixERlWHy5MkQBAE7d+7E/Pnz4erqirCwMAwfPhzh4eFil2dAqVRi3bp1WLhwIWJjYxEdHY02bdpg7dq1+Pjjj/Hw4cNyHWf+/Pno1KkTtm7ditWrV0OlUsHDwwOhoaF49dVXoVQqERERgX/+85+ws7ND9+7dy3XcQYMGYeHChSgsLDT4gidgutf7448/houLC7Zv346FCxfCy8sL//rXv3Djxg2DL1d++eWX+Oqrr3DkyBHs3r0bXl5eeOeddyCXyzF79my9vu3bt8d7772HrVu34pNPPoFarcaMGTPKDOV2dnbYsmULli5diiNHjiAyMhLOzs4YPXo03nrrrQrfRba8Lly4UOrKNUqlElOmTEFAQAC2bt2KpUuXYsuWLbh//z4aNWqE9957D6+++qquv6+vL/r164czZ85g//790Gq1cHd3x9SpU/X6vfrqqzh+/Dg2bNiAvLw8ODs7o23btpg6dareCi9EJB6JUB3f0iEiIj0ajQYvvPAC2rRpU+kb8BARUe3BOeVERCZW2mj41q1bkZubW+q63EREVPdw+goRkYnNmTMHRUVFCAwMhFKpxO+//44ffvgBTZo0wahRo8Quj4iIzACnrxARmdiePXuwadMmXL9+Hffv34ezszN69uyJWbNmwcXFRezyiIjIDDCUExERERGJjHPKiYiIiIhExlBORERERCQyftHzkXv3CqDVVu9MHmdnW2Rm5lfrOalu4TVGpsTri0yJ1xfVRlKpBE5ONqVuYyh/RKsVqj2Ul5yXyJR4jZEp8foiU+L1RXUJp68QEREREYmMoZyIiIiISGQM5UREREREImMoJyIiIiISGUM5EREREZHIuPoKERER0TM8eFCA/PwcaDQqsUshMyWTKWBr6wArq9KXOywPhnIiIiKiMqhURcjLuwdHRxcoFBaQSCRil0RmRhAEqFSFyM6+C7lcAYVCWanjcPoKERERURny8rJha+sApdKSgZxKJZFIoFRawsbGAfn52ZU+DkM5ERERURnU6iJYWFiJXQbVAJaWVlCpiiq9P6eviODXP28j8ngSsnILUc/eAsN6eqNLqwZil0VERERP0Wo1kEplYpdBNYBUKoNWq6n0/gzl1ezXP29jXXQCitRaAEBmbiHWRScAAIM5ERGRGeK0FSqPql4nnL5SzSKPJ+kCeYkitRaRx5NEqoiIiIiIxGZWoXzlypXw9fXFkCFDytU/PT0ds2bNQocOHRAUFIQ333wTKSkpJq6yajJzCyvUTkRERFTTzJgxBTNmTKn2fWsys5m+kpGRgRUrVsDa2rpc/QsKCjB+/HgUFBRg2rRpkMvlWLt2LcaPH489e/bAwcHBxBVXjrO9RakB3NneQoRqiIiIqC7p3r1Dufrt2LEP7u4NTVwNPclsQvlXX32F1q1bQxAE5ObmPrf/5s2bcePGDURGRqJly5YAgB49emDQoEFYu3YtZs2aZeqSK2VYT2+9OeUlBnXzEqcgIiIiqjM++WSu3uPt27cgPT0Nb731rl67o6NTlc6zZMk3ouxbk5lFKL948SL27duHXbt2YcGCBeXaJyYmBu3atdMFcgDw9vZGly5dEB0dbbahvOTLnCWrr9hZK5B7X4WbGfdFroyIiIhqu5CQcL3Hx47FIicn26D9aQ8fPoSlpWW5z6NQKCpVX1X3rclED+WCIGDevHkYOnQo/P39y7WPVqtFYmIiIiIiDLYFBATg5MmTePDgAayszHNd0S6tGqBLqwZwdbVDRkYeNhxMxOGzKejU0g3eDc1z2g0RERHVDTNmTEF+fj7ef/8jLFu2BImJCRg7djwmT56Kn38+hn37duPKlUTk5ubA1dUN4eGDMG7cJMhkMr1jAMDy5d8DAM6fP4uZM6dh/vyF+OuvZOzZswu5uTkICGiLf/7zI3h6NjLKvgCwa9d2bN26CZmZd+Ht7Y0ZM97BypUr9I5pjkQP5Xv27MG1a9fwzTfl/1NFdnY2ioqK4OrqarDN1dUVgiAgIyMDjRs3NmapJjOipzf+uHoXa6MT8OnEjpDLzOr7t0RERGREJfcrycwthLOZ3q8kO/se3n//HfTvH4rQ0AGoX7+4vqioH2BlZY2IiLGwtrbCuXNnsWrVdygoKMD06c+fpbBu3WpIpTKMGTMeeXm52LJlAz7/fA5WrlxnlH13796JJUsWol27IEREvIy0tDTMnv0e7Ozs4OrqVvkXpBqIGsrz8/Px1VdfYcqUKXBzK/8LVVhY/EVJpVJpsM3CovgLkw8fPqxQLc7OthXqbyyurnYAgLdGtcPc1adx7OJtvNzfV5RaqHYqucaITIHXF5mSOVxfd+5IIZcbb7Dsl8tpWHcgAUWqJ+5XciABMpkEXVu7G+085VWytvaTz1EikeDu3Qx8/PG/MGjQUL3+8+Yt0JvGMmLEKHzxxXzs3r0Db7wxXZfNnj6u7NGAo0ajwf/+tx5yefEUFUdHRyxZ8iVu3EiGt3fzKu2rUqmwatV3aN06AMuXfwe5vDjm+vj4YN68T+HmVt+o/5alkUqllb5uRQ3lK1asgEKhwKRJkyq0X0nwLioyvJVpSWCvyLwnAMjMzIdWK1Ron6oqmb4CAF6uNujcsj62HUqEfyMHeLjYVGstVDs9eY0RGRuvLzIlc7m+tFot1E8tznDyUhpOXEyr1PGSbuVArdHPG0UqLVbtj8PRczcrdKzubdzRLaBqQV4Qimt58jkKggBLS0v06xdu8NzlcqWu7f79AhQVqRAQ0A67d+9CUlIyWrTwKfW4Gk3x/4aHDwIg07UHBLQFAKSkpKBJk2ZV2vfy5cvIycnGm2/OBCDV9QsODsHXX38FQRAMno+xabXaZ163UqmkzIFg0UL5nTt3sG7dOsyaNQt3797VtRcWFkKlUiE1NRV2dnalLm3o6OgIpVKJjIwMg20ZGRmQSCSlTm0xdy/3bYE//8rC2uh4zB7bHlIp7yBGRERUmzwdyJ/XLhZXVzfdSPOTkpOTsHLlCpw//xsKCgr0thUU5D/3uCXTYErY2dkDAPLynv8B7Hn73r5d/EHp6Tnmcrkc7u7V/1eIihItlGdmZkKlUmHRokVYtGiRwfbg4GC8/vrreO+99wy2SaVS+Pj44PLlywbbLl68iCZNmpjtlzyfxd5aiZeDW2DlD3GIPZ+Kfh0aPX8nIiIiqlbdAio/Qv3Pb0+Web+SD8YGVbU0o7GwMJxxkJeXh7femgJra1tMnjwNHh6eUCqVuHIlAStWLINW+/xRaKlUVmp7yei4qfatCUQL5Z6enqV+ufPrr7/G/fv38dFHH8HLywsAcOvWLTx48ADe3t66fiEhIVi8eDHi4uJ0yyImJyfj1KlTeP3116vlOZjCC63q41RcOiKPJyOwhQtcHGrehwsiIiIqXWn3K1HKpRjW0/sZe5mH338/h5ycHMyf/yXatXv8ASIt7ZaIVT3WoEHxB6XU1BS0bRuoa1er1UhLS9PNWTdXooVyOzs79O3b16B93bp1kMlkets++OADnDlzBomJibq2MWPGYMeOHZgyZQomTSpehmft2rVwdXXFxIkTq+MpmIREIsH4EF/MWX0a6w8k4p1RbXVfeCAiIqKa7cn7lZjz6iulkUqLvyT55Mi0SqXC7t07xCpJj59fSzg4OGDfvt0ICQnXTb85dOgA8vKef2NKsYm+JGJl2draYsOGDViwYAG+/fZbaLVadO7cGR9//DGcnKp2FyqxOTtYYkRPb2w6dAW//nlblG9jExERkWmU3K+kpgkIaAM7O3vMn/8ZRoyIgEQiQUxMFMxl9ohCocCrr07BkiVf4u2330Tv3sFIS0tDdPR+eHh4mv0gp9mF8g0bNpSrDQAaNGiApUuXmrokUfQO8sDpuHRsOXwVrZs6w97GcPlHIiIiouri4OCIhQuXYPnyr7Fy5QrY2dmjf/8wdOjQCe++O0Ps8gAAw4dHQBAEbN26Cd988194e7fAf/6zGF9/vQhKpYXY5T2TRKgts+OrSOwlEUtz624BPltzBkE+rpg2pHU1Vka1hbksKUa1E68vMiVzub5u376BBg2aiF0GVYFWq8XAgf3Qs2dvfPDBHJOe63nXy7OWROStI81YQxcbDOzqhTPxd/DHtbvP34GIiIioDiu5X82TDhz4Ebm5OQgMbC9CReVndtNXSF/4C03wW8IdbIhJhG8jR1hZ8J+MiIiIqDQXL/6BFSuWoVevPrC3d8CVKwn48cd9aNbMG717Gy4wYk6Y8MycXCbFpDB/zN9wFjuOJWF8iK/YJRERERGZpYYNPeDi4oqdO7chNzcH9vYOCA0dgGnTZkChUIhd3jMxlNcAzRrao1+HRjj4Wwo6+7vBt3HNXl2GiIiIyBQ8PDyxcOESscuoFM4pryFe6tEMLg6WWHsgESq1RuxyiIiIiMiIGMprCAulDBPC/JCedR/7Tl4XuxwiIiIiMiKG8hqklVc9dA9wR/Spv/F3uvjLRBERERGRcTCU1zARwc1ha63AmqgEaLRascshIiIiIiNgKK9hbCwVeKWfD26k5+Hgbylil0NERERERsBQXgO193VFYAsX7Pn5L6Tfuy92OURERERURQzlNZBEIsEr/X0hl0mxLjoBgiCIXRIRERERVQFDeQ3lZGeBUb29kfB3Nn66cEvscoiIiKiOioraj+7dOyAt7XEeGTFiEObP/6xS+1bV+fNn0b17B5w/f9Zox6wODOU12IttG8KvsSO2H03CvbxCscshIiKiGuD9999B377d8eDBgzL7vPvuDISE9ERhofnmi8OHY7B9+2axyzAahvIaTCKRYEKYH9QaLTYeTOQ0FiIiInqufv1C8PDhQ5w4cbzU7ffuZeHcud/w4ou9YWFhUalzbN68Cx98MKcqZT5XbOxBbN++xaC9XbsgxMaeRLt2QSY9v7ExlNdw9Z2sMbRHU/x+9S7OJWaIXQ4RERGZuR49esHKyhqHD8eUuv3IkcPQaDTo3z+00udQKpWQy+WV3r8qpFIpLCwsIJXWrJgrzqtFRtW/YyOcib+DjYeuwK+JE2ytFGKXRERERGbK0tISPXr0xNGjh5Gbmwt7e3u97YcPx8DZ2RmNGjXBokX/wblzZ5Ceng5LS0sEBXXA9Omz4O7e8JnnGDFiEAID2+Pjjz/TtSUnJ+Hrr7/E5cuX4ODggCFDhsHFxdVg359/PoZ9+3bjypVE5ObmwNXVDeHhgzBu3CTIZDIAwIwZU/DHH+cBAN27dwAANGjgjp079+P8+bOYOXMali79DkFBHXTHjY09iI0b1+LGjeuwtrZBt2498MYbM+Ho6KjrM2PGFOTn5+Nf/5qLxYsXIj7+T9jZ2WPkyNEYO3ZCxV7oCmIorwVkUikmhflh7tqz2H7kGl4d4C92SURERFSGM7fPY1/SAdwrzIaThSMGe4eiU4PqnWrRr18oDh6MxrFjsRg8+CVd++3babh8+SJGjBiN+Pg/cfnyRfTtGwJXVzekpd3Cnj278NZbU7Fx4w5YWlqW+3yZmXcxc+Y0aLVavPLKBFhaWmHfvt2lTo+JivoBVlbWiIgYC2trK5w7dxarVn2HgoICTJ8+CwAwYcKrePDgAdLT0/DWW+8CAKysrMs8f1TUfixY8DlatQrAG2/MxJ076di1axvi4//EypXr9erIzc3BP/4xE717ByM4uD+OHj2MFSuWoVmz5ujSpVu5n3NFMZTXEo3r2yHshcb48dcb6NyqPlp51RO7JCIiInrKmdvnsTlhF1RaFQDgXmE2NifsAoBqDeYdO3aGo6MTDh+O0Qvlhw/HQBAE9OsXAm/v5ujdu6/eft26vYhp0ybh2LFYhIYOKPf5Nm1ah5ycbKxatQG+vn4AgLCwgXj55ZcM+n722b9hYfE48A8dOgJffrkAu3fvwOuvvwGlUomOHV9AZOQO5ORkIyQk/JnnVqvVWLFiGZo398GyZf8HpVIJAPD19cNnn32M/ft3Y8SI0br+d+6k49NP/41+/Yqn7wwcOAQjRgzEjz/uZSin8hnczQtnEzOwLjoB8yZ3hoVSJnZJREREtc7ptHP4Ne23Su37V87fUAtqvTaVVoVN8Tvxy60zFTpWF/eO6OzevlJ1yOVy9OnTF3v27MLdu3fh4uICADh8+CA8PRuhZcvWev3VaszXmAQAACAASURBVDUKCvLh6dkItrZ2uHIloUKh/NdfTyIgoK0ukAOAk5MT+vULw+7dO/T6PhnI798vQFGRCm3bBmLv3kjcuHEdLVr4VOi5JiTE4d69LF2gL9GnTz98881/8csvJ/VCua2tLfr2DdE9VigU8PdvhVu3blbovBXFUF6LKOQyTAz1xRebf8fun5MxOriF2CURERHRE54O5M9rN6V+/UIRGbkDR44cxKhRY3D9+l+4du0KJk16HQBQWPgQGzasRVTUfmRk3NFb5S0/P79C50pPv42AgLYG7Y0bNzFoS05OwsqVK3D+/G8oKCjQ21ZQULHzAsVTcko7l1QqhadnI6Snp+m1u7nVh0Qi0Wuzs7NHUtK1Cp+7IhjKaxnfxk7oHeiBQ2dT0Mm/Ppo1tH/+TkRERFRund3bV3qEes7JBbhXmG3Q7mThiLeDplW1tAoJCGgLd3cPHDp0AKNGjcGhQwcAQDdtY8mSLxEVtR8jR76M1q0DYGtrC0CCzz77yGTLMOfl5eGtt6bA2toWkydPg4eHJ5RKJa5cScCKFcug1WpNct4nSaWlzzQw9dLTDOW10Ihe3vjj2l2siY7HpxM7Qi6rWUsCERER1VaDvUP15pQDgEKqwGDvyi8/WBV9+/bHhg1rkJqagtjYg/D19deNKJfMG3/rrXd0/QsLCys8Sg4A9es3QGpqikH733/f0Hv8++/nkJOTg/nzv9RbZ7z0O35KSmkz1KCBu+5cTx5TEASkpqagaVPvch3H1JjWaiErCznGhfjiZkYBok7deP4OREREVC06NQjCGL/hcLIoXobPycIRY/yGV/vqKyX69w8DACxfvgSpqSl6a5OXNmK8a9c2aDSaCp+nS5duuHTpAhITE3Rt9+7dw6FD0Xr9StYWf3JUWqVSGcw7BwArK6tyfUDw82sJJ6d62LNnJ1Sqxx+Gjh6NRUbGHXTtarovb1YER8prqXbNXdDJ3w0//HIdHXzd0NDFRuySiIiICMXBXKwQ/rSmTZuheXMfnDjxE6RSKYKDH3/BsWvX7oiJiYKNjS28vJrizz8v4ezZM3BwcKjwecaMmYCYmCi8++50jBgxGhYWlti3bzfq13dHfv5VXb+AgDaws7PH/PmfYcSICEgkEsTERKG0mSO+vn44eDAay5Ythp9fS1hZWaN79xcN+snlcrzxxltYsOBzvPXWVPTt2x937qRj585taNbMG4MGGa4AIwaOlNdiY/r6wEIhw9roBGhNPA+KiIiIaqaS0fHAwPa6VVgAYNas9xASEo5Dh6KxfPnXuHv3Lr7++ptnrgdeFhcXFyxd+n9o2tQbGzasxY4dWxAaGo6RI0fr9XNwcMTChUvg7OyClStXYMuWjejQoTPefHOmwTGHDBmOkJAwREX9gM8/n4Ovv/6yzPOHhw/CZ5/NR2HhQ3zzzX8RFbUf/fqF4r///a7UtdLFIBFMPWu9hsjMzIdWW70vhaurHTIy8kx6jl8up2HVD/EY288Hwe09TXouMj/VcY1R3cXri0zJXK6v27dvoEEDwxVCiErzvOtFKpXA2dm29G2mKorMQ5dWDdC6aT3sPJaEuzkPxC6HiIiIiErBUF7LSSQSjA/1BQCsj0k0+XI+RERERFRxDOV1gIuDFYb3bIbLyVk49We62OUQERER0VMYyuuIPkGe8Pawx5bYq8i9XyR2OURERET0BIbyOkIqlWBimD8eFqmx5fDV5+9ARERERNWGobwO8XCxwcAuXjgdl44L1+6KXQ4RERERPcJQXseEd2kCD1cbrI9JxINCtdjlEBEREREYyuscuUyKiWF+yM4rxM7jSWKXQ0REZPa4chmVR1WvE4byOsi7oQP6dmiEo+dv4kpKttjlEBERmS2ZTA6Vigsk0POpVEWQyeSV3p+hvI4a9mIzuDhYYk10AlRqjdjlEBERmSVbW0dkZ2egqKiQI+ZUKkEQUFRUiOzsDNjaOlb6OJWP81SjWShlGB/qi8XbLmDfyesY3tNb7JKIiIjMjpWVDQAgJ+cuNBp+F4tKJ5PJYWfnpLteKoOhvA5r3dQZ3QIa4MDpv9HRzw2N69uJXRIREZHZsbKyqVLYIioPTl+p4yL6tICNlQJrohOg0WrFLoeIiIioTmIor+NsrRQY288HN27n4dBvqWKXQ0RERFQnMZQTOvi6IrCFC/b8nIw79+6LXQ4RERFRncNQTpBIJHilvy9kMgnWRifw2+VERERE1YyhnAAATnYWGNm7ORL+zsbPF9PELoeIiIioTmEoJ50X2zaEbyNHbDtyDffyCsUuh4iIiKjOYCgnHalEgolhflBrtNh06IrY5RARERHVGaKtU37p0iV89913iIuLQ2ZmJuzs7ODn54fp06cjKCjomfsuW7YMy5cvN2h3cXHByZMnTVVynVC/njWGdm+KHceScDbhDjr4uYldEhEREVGtJ1ooT0lJgUajwciRI+Hq6oq8vDzs378fr7zyClauXIlu3bo99xhz586FpaWl7vGTP1Pl9e/UCGfi72DToSvw93KCjaVC7JKIiIiIajXRQnl4eDjCw8P12l5++WX07dsX69evL1coDwsLg729valKrLNkUikmhfth7tqz2HbkGl4N9xe7JCIiIqJazazmlFtZWaFevXrIzc0tV39BEJCfn88l/EygcX07hHZujBMX0xB3PUvscoiIiIhqNdFDeX5+PrKyspCcnIzFixfjypUr6NKlS7n27dWrF9q3b4/27dtj9uzZyM7ONnG1dcvgbl6o72SFdQcSUFikEbscIiIiolpLtOkrJT766CPExMQAABQKBUaPHo1p06Y9cx97e3uMGzcObdu2hUKhwKlTp7Bt2zbExcVhx44dUCqV1VF6radUyDAxzA9fbP4du39OxujgFmKXRERERFQrSQSR534kJibi7t27uH37Nvbu3QsPDw/MmTMHNjY2FTrOpk2bMHfuXMybNw+jRo0yUbV10zc7L+Dgqev4cuaL8GnsJHY5RERERLWO6KH8SSqVCsOHD4eXlxeWLl1aoX21Wi2CgoLQu3dvLFmypMLnzszMh1ZbvS+Fq6sdMjLyqvWclXH/oRpzVp2CrZUC/5rYEXKZ6LOeqJxqyjVGNROvLzIlXl9UG0mlEjg725a+rZpreSaFQoHg4GAcPHgQDx8+rNC+UqkU9evXR05Ojomqq7usLeUYH+KH1IwCRJ+6IXY5RERERLWOWYVyAHj48CEEQUBBQUGF9lOpVEhLS4OTE6dXmEK7Fi7o5O+G/b9cx627Ffu3ISIiIqJnEy2UZ2UZLrOXn5+PmJgYuLu7w9nZGQBw69YtJCUlPXff1atXo7CwED169DBNwYQxfX1goZBh7YEEaM1n1hMRERFRjSfa6itvv/02LCwsEBgYCFdXV6SlpSEyMhK3b9/G4sWLdf0++OADnDlzBomJibq23r17Izw8HD4+PlAqlTh9+jRiYmLQvn17DBw4UIynUyfY2ygxOrgFVv8Yj6PnbyK4vafYJRERERHVCqKF8sGDB2Pv3r3YsGEDcnNzYWdnh3bt2mHhwoXo1KnTM/cdNGgQzp8/jwMHDkClUsHDwwNvvvkmpk6dCrlc9FUea7WurRvgVFw6dh5PQrvmLnB2sBS7JCIiIqIaz6xWXxETV18pv7vZD/DJ6jPwaeSIt0e2gUQiEbskKkNNvcaoZuD1RabE64tqoxqz+grVDC6OVhj2YjNcSs7Eqbh0scshIiIiqvEYyqlSgtt7ollDe2w5fBW594vELoeIiIioRmMop0qRSiWYFOaHB4VqbD18VexyiIiIiGo0hnKqNA9XWwzs6oVTcem4cO2u2OUQERER1VgM5VQlA7o0gYeLDTYcTMSDQrXY5RARERHVSAzlVCVymRQTw/xwL7cQu44nPX8HIiIiIjLAUE5V5u3hgOAOnjh6/iaupGSLXQ4RERFRjcNQTkYx7MVmqGdvibXRCVCpNWKXQ0RERFSjMJSTUVgq5ZgQ5ovbWfex/5frYpdDREREVKMwlJPRtG7qjK6tGyD61N9IuZMvdjlERERENQZDORnV6OAWsLaUY01UPDRardjlEBEREdUIDOVkVLZWCozt54Prt/Nw6LdUscshIiIiqhEYysnoOvq5oV1zF+z5ORl37t0XuxwiIiIis8dQTkYnkUgwLsQXMpkE6w4kQhAEsUsiIiIiMmsM5WQSTnYWGNmrOeJv3MOJi2lil0NERERk1hjKyWRebNcQPo0csfXINWTnF4pdDhEREZHZYignk5FKJJgY5geVWotNB6+IXQ4RERGR2WIoJ5NqUM8aQ7p74dyVDJxLvCN2OURERERmiaGcTC6kU2M0drPFxoNXUPBQJXY5RERERGaHoZxMTi6TYlK4P/Luq7D9yDWxyyEiIiIyOwzlVC2aNLBDSOdG+PliGuKvZ4ldDhEREZFZYSinajOkW1PUd7LC2gMJKFRpxC6HiIiIyGwwlFO1USpkmBjmh4zsh9j7819il0NERERkNhjKqVr5NnZCz3YNEfPb3/grLVfscoiIiIjMAkM5VbuRvZrDwUaJNVEJUGu0YpdDREREJDqGcqp21pZyjOvvi9SMfESf/lvscoiIiIhEx1BOogj0cUUHPzfsP/kX0jILxC6HiIiISFQM5SSasf18YKGQYW10ArSCIHY5RERERKJhKCfRONgoMTq4Ba6m5uDY7zfFLoeIiIhINAzlJKqurRugVdN62HEsCZk5D8Uuh4iIiEgUDOUkKolEggkhvhAEARsOJkLgNBYiIiKqgxjKSXQujlYY9qI3LiZl4nRcutjlEBEREVU7hnIyC33be6JZQ3tsPnwVefeLxC6HiIiIqFoxlJNZkEolmBjmhweFamyJvSp2OURERETViqGczIanqy0GdGmCU3+m42JSptjlEBEREVUbhnIyKwO6eMHd2RrrYxLwoFAtdjlERERE1YKhnMyKQi7FpHB/3MstROTxZLHLISIiIqoWDOVkdpp7OCC4vSeOnE/F1dRsscshIiIiMjmGcjJLw3o2Qz17S6yNToBKrRG7HCIiIiKTYigns2SplGNCqC/SMu9j/y83xC6HiIiIyKQYyslstW7mjC6tGiD61A2k3MkXuxwiIiIik2EoJ7P2ct8WsLaUY210PLRaQexyiIiIiEyCoZzMmq2VAmP6+uCvtDwcOpsidjlEREREJsFQTmavk78b2no7Y/dPybiT/UDscoiIiIiMjqGczJ5EIsG4EF9IpRKsP5AAQeA0FiIiIqpdGMqpRqhnb4mRvZsj7vo9nLiUJnY5REREREbFUE41Rs92DeHTyBHbYq8hO79Q7HKIiIiIjEa0UH7p0iVMnz4dvXv3Rps2bdCtWzdMnjwZ58+fL9f+6enpmDVrFjp06ICgoCC8+eabSEnhFwFrM6lEgolhfihSa7Hp0BWxyyEiIiIyGtFCeUpKCjQaDUaOHIlPPvkEkydPRlZWFl555RWcPHnymfsWFBRg/PjxOHfuHKZNm4aZM2ciLi4O48ePR05OTjU9AxJDg3rWGNLdC+cSM3AuMUPscoiIiIiMQi7WicPDwxEeHq7X9vLLL6Nv375Yv349unXrVua+mzdvxo0bNxAZGYmWLVsCAHr06IFBgwZh7dq1mDVrlklrJ3GFdGqM3+LvYOOhRPg3cYS1pULskoiIiIiqxKzmlFtZWaFevXrIzc19Zr+YmBi0a9dOF8gBwNvbG126dEF0dLSpyySRyWVSTAz3Q25BEbYfvSZ2OURERERVJnooz8/PR1ZWFpKTk7F48WJcuXIFXbp0KbO/VqtFYmIiWrdubbAtICAA169fx4MHXMu6tvNqYI+QTo3x04U0xN+4J3Y5RERERFUi2vSVEh999BFiYmIAAAqFAqNHj8a0adPK7J+dnY2ioiK4uroabHN1dYUgCMjIyEDjxo1NVjOZhyHdm+J8YgbWRSfg88mdYKGQiV0SERERUaWIHsqnT5+OiIgI3L59G3v37kVRURFUKhWUSmWp/QsLi5fCK227hYUFAODhw4cVrsPZ2bbC+xiDq6udKOetLWa9HIiPV/yCQ+duYtKgVmKXY5Z4jZEp8foiU+L1RXWJ6KHc19cXvr6+AIDBgwdj+PDhmD17NpYuXVpq/5LgXVRUZLCtJLBbWlpWuI7MzHxotdV7p0hXVztkZORV6zlrG3cHS7zYtiF2H7+GVk0c0dTdXuySzAqvMTIlXl9kSry+qDaSSiVlDgSLPqf8SQqFAsHBwTh48GCZo92Ojo5QKpXIyDBcDi8jIwMSiaTUqS1Ue43q7Q17GyXWRCVArdGKXQ4RERFRhZlVKAeKp54IgoCCgoJSt0ulUvj4+ODy5csG2y5evIgmTZrAysrK1GWSGbG2VGBcf1+kZuTjwOm/xS6HiIiIqMJEC+VZWVkGbfn5+YiJiYG7uzucnZ0BALdu3UJSUpJev5CQEPzxxx+Ii4vTtSUnJ+PUqVMIDQ01beFkloJ8XNHB1xX7Tl5HWmbpH+iIiIiIzJVEEIQqT6RWq9WIjY1FTk4OevfuXa7pI+PHj4eFhQUCAwPh6uqKtLQ0REZG4vbt21i8eLHuxkLjxo3DmTNnkJiYqNs3Pz8fL730Eh48eIBJkyZBJpNh7dq1EAQBe/bsgZOTU4WfA+eU13w5+YWYs+o0GrrY4IOxQZBKJGKXJDpeY2RKvL7IlHh9UW30rDnlFf6i58KFC3H69Gns2rULACAIAiZNmoSzZ89CEAQ4Ojpi+/btz12ScPDgwdi7dy82bNiA3Nxc2NnZoV27dli4cCE6der0zH1tbW2xYcMGLFiwAN9++y20Wi06d+6Mjz/+uFKBnGoHB1sLjOrTHGuiEnD895voHeQpdklERERE5VLhkfJBgwaha9eumD17NgAgNjYW06dPx2uvvQZ/f3/MmzcPffv2xb///W+TFGwqHCmvHQRBwFfb/kDyrVz8+7XOqGdf8ZV4ahNeY2RKvL7IlHh9UW1k1NVXbt++jSZNmugeHz16FJ6ennjvvfcwYMAAjB49Gr/++mvlqyWqAolEgvGhftAKAtbHJMIIs7OIiIiITK7CoVylUkEufzzr5fTp0+jatavucaNGjUpdrpCourg5WmFYj2a4mJSJ0/HpYpdDRERE9FwVDuUNGjTA77//DgC4evUqUlJS0LFjR932zMxMWFtbG69Cokro26ERmrrbY/Ohq8i7b3ijKSIiIiJzUuFQPmDAAOzZswdTp07F1KlTYWtri549e+q2x8fHP/dLnkSmJpVKMCnMDw8K1dgae1XscoiIiIieqcKhfOrUqXjppZfwxx9/QCKR4IsvvoC9ffGtzfPy8nDkyBF06dLF6IUSVZSnmy3CX2iCX/9Mx6XkTLHLISIiIiqTUdYpL6HValFQUABLS0soFApjHbZacPWV2kml1uKzNWdQpNJg7uTOsLKo8CqgNRqvMTIlXl9kSry+qDYy6uorz6JWq2FnZ1fjAjnVXgq5FJPC/JGVW4jIn5LFLoeIiIioVBUO5cePH8eyZcv02jZt2oSgoCC0a9cO//jHP6BSqYxWIFFVNfd0QJ8gTxw5l4prN3PELoeIiIjIQIVD+erVq5Gc/HjEMSkpCQsWLICbmxu6du2KqKgobNq0yahFElXVsJ7NUM/eAmui4qFSa8Uuh4iIiEhPhUN5cnIyWrdurXscFRUFCwsL7Ny5E6tWrUJ4eDj27Nlj1CKJqsrKQo7xoX5Iy7yPH365LnY5RERERHoqHMpzcnLg5OSke/zLL7/ghRdegK1t8aT1Tp06ITU11XgVEhlJQDNndGlVH1GnbiD1Tr7Y5RARERHpVDiUOzk54datWwCA/Px8XLp0CR06dNBtV6vV0Gg0xquQyIhGB7eAlYUca6ITqn21HSIiIqKyVDiUt2vXDlu3bsWBAwewYMECaDQavPjii7rtN27cgJubm1GLJDIWO2slxvRrgb/ScnH4bIrY5RAREREBqEQonzlzJrRaLd5++21ERkZi6NChaN68OQBAEAQcPnwYQUFBRi+UyFg6+9dHG29nRP6cjIzsB2KXQ0RERIQK30mlefPmiIqKwvnz52FnZ4eOHTvqtuXm5mLChAno3LmzUYskMiaJRILxIb6Ys+o01h1IwD8i2kEikYhdFhEREdVhRr2jZ03GO3rWPUfOp2LjwSt4Ndwf3du4i12OSfAaI1Pi9UWmxOuLaqNn3dGz0vcc//vvvxEbG4uUlOJ5uY0aNUJwcDAaN25c2UMSVategR44HZeObUeuIqBZPTjYWohdEhEREdVRlRop//rrr7Fy5UqDVVakUimmTp2KWbNmGa3A6sKR8ropLbMAn/7vN7Rr7ow3XwoQuxyj4zVGpsTri0yJ1xfVRkYdKd+5cye+++47BAYG4rXXXkOLFi0AAFevXsXq1avx3XffoVGjRhg2bFjVqiaqBu7ONhjczQuRPyXj/JUMBPm4il0SERER1UEVHikfNmwYFAoFNm3aBLlcP9Or1WqMHTsWKpUKkZGRRi3U1DhSXnepNVrMW3cWufeLMP+1zrC2VIhdktHwGiNT4vVFpsTri2qjZ42UV3hJxKSkJISHhxsEcgCQy+UIDw9HUlJSxaskEolcJsXEMD/kFhRh+1Feu0RERFT9KhzKFQoF7t+/X+b2goICKBS1Z6SR6oam7vYI6dgYP124hYQb98Quh4iIiOqYCofygIAAbNu2DXfv3jXYlpmZie3bt6Nt27ZGKY6oOg3p0RRujlZYeyABRSrN83cgIiIiMpIKf9HzzTffxMSJExEeHo7hw4fr7uZ57do1REZGoqCgAIsWLTJ6oUSmZqGQYUKoL77c+gf2nvgLI3s3F7skIiIiqiMqHMo7duyIZcuWYd68eVizZo3etoYNG+KLL75Ahw4djFYgUXXy96qHHm3cEXMmBR393eDVwF7skoiIiKgOqNTNg/r06YNevXrh8uXLSE1NBVB886BWrVph+/btCA8PR1RUlFELJaouEX2a42JyJtZEJeCTCR0gl1V4lhcRERFRhVT6jp5SqRRt2rRBmzZt9Nrv3buHv/76q8qFEYnF2lKBV/r54pvdlxBz5m8M6OIldklERERUy3EIkKgU7X1d0d7XFXtPXEdaZoHY5RAREVEtx1BOVIZX+vlAKZdiXXQCtBW7xxYRERFRhTCUE5XBwdYCEX2a40pqDo7/cUvscoiIiKgWYygneobubdzh38QJO45eQ1buQ7HLISIiolqqXF/0fHrpw2c5f/58pYshMjcSiQQTwvzwr1WnsfHgFbw1PAASiUTssoiIiKiWKVco/+KLLyp0UIYWqk3cHK0wtEczbD96Db8l3EEn//pil0RERES1TLlC+fr1601dB5FZ69fRE78lpGPToSto6VUPtlYKsUsiIiKiWqRcobxTp06mroPIrMmkUkwM88fctb9hy+GreH1QS7FLIiIiolqEX/QkKqdGbrYIe6EJfv3zNi4lZ4pdDhEREdUiDOVEFTCoqxfcna2x/kACHhapxS6HiIiIagmGcqIKUMilmBjmh6zcQkQeTxa7HCIiIqolGMqJKqiFpyN6B3kg9lwqrt3MEbscIiIiqgUYyokqYXhPbzjZW2BtdAJUaq3Y5RAREVENx1BOVAlWFnKMD/HFrbsF+PHX62KXQ0RERDUcQzlRJbXxdsELLevjx19vIDUjX+xyiIiIqAZjKCeqgtF9W8DKQo610QnQagWxyyEiIqIaqlw3DyKi0tlbKzGmbwt8vz8Oh8+lon/HRmKXRERERGU4c/s89iUdwL3CbDhZOGKwdyg6NQgSuywAHCknqrLOLeujjbczIn9KQkb2A7HLISIiolKcuX0emxN24V5hNgDgXmE2Nifswpnb50WurBhHyomqSCKRYFx/X8xZfRrrDyTg3Yh2kEgkYpdFRERUo2i0GqgFDdRaNVRaFdTa4p/VWjXUghoqTfH/Frdp9Ps8aleV9H/UR9cmqHH5bhxUWv0b/6m0KuxLOmAWo+UM5URG4OxgiRE9vbHp0BX8cvk2ugW4i10SERHRMwmCoAvBJf+pngjBj9tK+jwOwSpBrbff4wD8qI9QyjEftRsE7kd9BBjnu1lSiRRyqRwKiRxyqQxyqQJyqdwgkJcoGTkXm2ih/OLFi9i9ezdOnz6NW7duwdHREYGBgXj77bfRpEmTZ+67bNkyLF++3KDdxcUFJ0+eNFXJRlMynym7MBuOZjafiSqvd5AHTsenY2vsVbRu5gwHG6XYJRER1Ti1/T1SK2hLGdFVQy1oDMKqXh/hydHhp0aB9UL0U32EUs6l1RQHbEFjtOcll8ohfxSCFVLFozAsLw7Hj7ZZKCwetT3VR/Koj95/xWFaIZE91f5EX8njwK144nxSSemzs+ecXFBqAHeycDTa61AVooXyVatW4fz58wgNDYWvry8yMjKwadMmDB06FDt37oS3t/dzjzF37lxYWlrqHj/5s7kqmc+k0qoAPJ7PBKBW/dKpi6QSCSaF+eHT/53B5kNX8MbQ1mKXRERUo5jiPVIQBGgEjeG0hlJGbMsOwU+N6gqlBFytRjdNQl1KCFY9CsFawTg3nJNKpI9CaWmB9lEIlilhI7UyDLWS0gLw4/BsEH5L+kjkpQZumURWI6ZtDvYO1bu+AEAhVWCwd6iIVT0mWiifOHEiFi1aBKXy8WhieHg4Bg0ahJUrV+I///nPc48RFhYGe3t7U5ZpdPuSDuhdDEDxfKbd135EU/smUMhKLnIFFM/4tEfmyd3ZBoO6emH3z3/hhSsZCPRxFbskIiJRaQUtVFo1VBoVVNqS/9QoevKxRoUirQo7ruwt9T1ya+JuXMtONhwdLplr/Ix5xOoypixUhryUUVv9MCuDtczqqdHcpwOu4Qjys0Nw6aPEzAcVV/LBzlxXXxEtlAcFGb4AXl5eaNGiBZKSksp1DEEQkJ+fDxsbmxrxCQ0oe95SblEePjv1hUG7VCKFQlryyVSu+1nvsUxeZS+L/AAAIABJREFU/Cce3f9Z9X9WPt0mK7uvQu+xvMa8ruYk7IUm+C0hAxsOJsK3sROsLfnVDSIyD4IgFAdkXRh+/LNhSC6j36PtpW97KnxrjDNFolBTiEt34/WnPjwxVcJKbvVUCJbp3iefDMH6o8SlTH0oMyAXT5Xge2LN16lBkNmE8KeZVVoQBAF3796Fn59fufr36tUL9+/fh42NDUJCQvDBBx/A0dE85gWVxcnCsdRgbqOwwfDmA3Wf7kvmgz3+5WnYptaoUagpQoGq4FHb477qR/9bVU/+YioJ7E/+/HSbXPb4g8OTHyLkUjmUpbQpZGX3lUqkNfIXoFwmxaRwP/x7/VnsOHYNE0LLdz0TUd1S8iW7p0eQS0aNVU+EX4Ow+8TjxyFZrReu1Vq1YYCuwvvCk4NECqkCStnj39cKqQKWSssntj3uVzx49KhdqtD9rJDKoZSVDDIVDyD994/vkVOYa3BuJwtH/LvbR1V5uYnMnlmF8n379iE9PR3vvPPOM/vZ29tj3LhxaNu2LRQKBU6dOoVt27YhLi4OO3bs0JsSY27Kms80osUgo39ye/yt6pJf4I/DeklwL9Iatqm0aqg1TwZ8/Q8GT7YVqO8/3q5R631o0FRxdEQCiUHAL32U/xkj/zI5nv4LQ5kfMow4daipuz36d2yEmDMpeKFlffg2dqrSa1FRtf2LUkSmoNFqSgnDj8Kt5tmhWff7UbfNMDTrQvITIbqyq03ofj+WEXZtFTaPHsuf2lbcV/4oND/eJtcF7bLCtEwqM/Irbmiod7hZz/klMiWJIAhmcW/wpKQkjBo1Cr6+vti4cSOk0ooFok2bNmHu3LmYN28eRo0aZaIqjePnG2ew5eJeZN7PgrN1PbzcZgh6NOkkdllGp9Vq9d/ANMXBXffmplGhSKNGkaZI9+fPIo3qqZ8f7aO3f9Gj7Y/e9DRPjCI9+rlIU4SqXtoyqezRG1bxG5PuzUv2eHTnyW1KWcn24lEiiSDD/p+uQyLI8EpIK1gpLR71kUMpUz4eJSrZp+QN8NEbZGX/SvDzjTP4v982oUhT9P/bu/foqOs7/+OvuU8yyeQ63AIEiRIU+MllLSKliuDWCyzotj+qgreW1RV3F1v72152f+f0YtdzVt22bula8CzQn6vtUhSXPYgX2FpBoRXlakACCDFAJhNyn8xMMvP7I8lkJjNBLsl8J5Pn45wcZr7fz3fynvg1eeWTz/f9jW6zW+x6+Lp7M/I8Q+ql4ntYOBxWsCOoYEeo6yP2cbJt8ftDnzsm2Gtc6LIuwOv8/777w97rsVW2uG3JxyRuS3zc/XkyeXnhUPkZCfSWFqHc6/Xq7rvvVjgc1m9+8xt5PBd/cVw4HNb06dM1d+5c/cu//MtFH+/zNSscTu2XwuPJldfblNLPOZR0dF3t3nu2P+kSoZjZrs8d27V0qGd2LPlfGy5X/Ax/778CJF86ZDfbtLN6t9o6Agmvl2XN0q3jbo4+N8nU9W/3BlPc9t7jYgcnHNv9PO7Q+DGmnoN7vW7vV4mtJUkNUtIw0vf7SXj1hOP7OjbZ8dGa+niN5HWe/2uR7PhoTT1F9T6kZ1tf7+c8/z16/zdLWn+S/2YHayu05dO34y6es5osmlMyS6XuMUnWHPf8Yp50OUXs2uWYJRiX85c2q8kSNzMc/aU35nn0/63uX7jNPb9o25PMFCfMIlu6l+Rd3i/R6Bs/I5GJzGaTiopyku4zfPlKU1OTli9frqamJr300kuXFMglyWw2a/jw4WpoaOjnCjFYWcwWWcwWGdEoM3bp0Po3PtYfD5/Wo3ddI0+hI2mAj3vc0dcvB4lLh7r/JB77i0OyQC5J/na/Xjn63yn+SmAoaI90aHvVu0n3WUyWJEsheh5nW7Ojwdgat9QiSWiO3R4NyfHj6EoBYLAyNJQHAgE98sgjOnHihNauXavx48df8muFQiGdPn1akyfTGxrGM5lMsnW1slp68xRVVLbqtbe9+of7/0xWy8AGhr5vjpCnf5j5LUmKWcXa+ajn72WRuP1x610jSbbFPO/9GknHRpIfe74aetcY/5q9xkb6OPYCa+i9P/F1InE7kq0H7uvr0ffX/Hw1JD829vi+/nsoyesn1nD+r0XsmO49v9q/LmFMt/8784n4GWqzNSXrkAEgExgWyjs6OrRy5Up99NFHWrVqlaZOnZp0XHV1tfx+f9zNhOrq6lRYWBg37oUXXlAgENCcOXMGtG7gYrmcNt17ywStevWAtu4+qTtmjRvQz9f3zRFuk9Oa/jfYQnrrq4NUgSNfw13DDKgIADKDYaH8qaee0rZt2zR37lzV19dr06ZN0X0ul0vz58+XJP393/+9du/ercOHD0f3z507V7fffrsmTJggu92uXbt2aevWrZoxY4YWLFiQ8vcCfJ4/mzhMMyZ4tOndE5pRPkwjCrMH7HPF3hyB7ivob+l+RzwAGKwMC+UVFRWSpO3bt2v79u1x+0pKSqKhPJmFCxdqz549ev311xUKhVRSUqJHH31UDz/8sKxWw5fJA0nd++cT9PHqXVq7pUL/555pMg/ghWHdN0fgQin0N37pA4CBkRbdV9IB3VeQCu/srdbaLRW678vlumlayYB/Ps4xDCTOLwwkzi9kovN1X+ESdSCF5vyvkbq6tED/+T9Hda4peZcUAAAw9BDKgRQymUy6/9ZydXRE9Outhy/7BkcAACAzEMqBFBtWkK3Fc8bro6O1+mNFjdHlAACANEAoBwxwy3WjVToiV//x5hE1+0OffwAAAMhohHLAABazWQ/eNlEtbe16+e1PjC4HAAAYjFAOGGTs8FzdOnOsdh44owPHfEaXAwAADEQoBwz0F7PHaURhtta9flhtwXajywEAAAYhlAMGslkteuC2ifI1tmnjO8eMLgcAABiEUA4YbMKYfM2dXqK3/1Slys8ajC4HAAAYgFAOpIGv3Fim/FyH1m6pUHtH2OhyAABAihHKgTSQ5bDqvi+X67PaFv33e58aXQ4AAEgxQjmQJq69slgzrxmuzTtP6DNvs9HlAACAFCKUA2nk7vlXKcth1b9vqVA4HDG6HAAAkCKEciCNuLPtunveVTpW3ai3P6gyuhwAAJAihHIgzVw/abimjC/S796pVG293+hyAABAChDKgTRjMpl035fLZTKZtG7rYUUiLGMBACDTEcqBNFSU59RXbizTweN12nngjNHlAACAAUYoB9LU3OklurIkTy+//YkaW4JGlwMAAAYQoRxIU2aTSQ/cNlGBUIf+460jRpcDAAAGEKEcSGOjil1acMM47f64Rh9+4jW6HAAAMEAI5UCau/36UpV4XPr11sNqbWs3uhwAADAACOVAmrNazHrwtqvV0BLUhv85anQ5AABgABDKgUFg/Ci3bvmzMfqfj6p1+OQ5o8sBAAD9jFAODBJ3zhmv4jyn1m6pUDDUYXQ5AACgHxHKgUHCYbfo/tsm6uw5v17bccLocgAAQD8ilAODyKRxhfrilJF6fddJfXqmyehyAABAPyGUA4PMknlXKifbpn/f8rE6wmGjywEAAP2AUA4MMi6nTUtvmaCTZ5u1dfcpo8sBAAD9gFAODEIzyj2adlWxNr17XGfrWo0uBwAAXCZCOTAImUwmLf3zclktZq3dUqFwJGJ0SQAA4DIQyoFBqiDXof89t0yHT9Xrnb3VRpcDAAAuA6EcGMS+dO0oTRybr//cflTnmgJGlwMAAC4RoRwYxEwmk+6/baLaOyL6f28cVoRlLAAADEqEcmCQG16QrcVzrtCHn9TqT4e9RpcDAAAuAaEcyAB/ft0YlY7I1YtvHFazP2R0OQAA4CIRyoEMYDGb9eBtE9Xsb9dv3v7E6HIAAMBFIpQDGWLs8Fzddv1Y7ThwRgeO+4wuBwAAXASr0QUA6D9/MXuc/nTYq1+9dlB2q0XnmgIqdDt0141lmjVphNHlAQCAPjBTDmQQm9Wi68o9ava3q64poIgkX2NA67ZU6L2DZ4wuDwAA9IFQDmSYZOE72B7Wb7YdVWsbF4ECAJCOWL4CZBhfY/KbCDW2BPXYT/+gvBy7RhW5NKrYpVFF2RpV7NLIYpfc2fYUVwoAALoRyoEMU+R2JA3mudk23fqFsaqubVG1r1Xv7j+tQLAjuj8ny6ZRRdkaWeyKhvaRRdkqyHXIZDKl8i0AADDkEMqBDHPXjWVat6VCwfZwdJvdatbX5l0Vd7FnJBLRuaaAqn0tqq5t1Wlfi6prW/Snihq1tLVHxzntlmhA7/y3M7AX5zllJqwDANAvCOVAhukO3ht/X6m6xr67r5hMJhW6nSp0OzX5iqLo9kgkoqbWkKprW7qCequqfS06cLxOO/b3rFe3W80aUZgdF9hHFbvkyc+S1cLlKgAAXAxTJBKJGF1EOvD5mhUOp/ZL4fHkyuttSunnxNDS3+dYa1tI1b7WziUwtS063fXY19gWHWMxmzS8MLszqMcsgxlZlC2b1dJvtcB4fA/DQOL8QiYym00qKspJuo+ZcgAXLNtp05UlebqyJC9ue1uwXWfqWuOCepW3RXuOeNX9a7/JJHnyszSqyKWRxT2BfURhtrIcfCsCAAxt/CQEcNmcdqvGjXBr3Ah33PZQe1hn61q71q13XmB62tei/cd86oj5y1Sh29EZ1otcGlXcs3Y9J8uW6rcCAIAhDAvl+/bt0yuvvKJdu3apurpa+fn5mjZtmlauXKnS0tLPPf7s2bP6yU9+oh07digcDuv666/Xd7/7XY0ZMyYF1QO4EDarWaOH5Wj0sPg/1XWEw/LWt8Usg+lcu36k6jMFQz0XqLpd9viOMF1r190uOx1hAAAZxbA15X/7t3+rPXv26NZbb1V5ebm8Xq9efPFFtba2asOGDSorK+vz2JaWFt11111qaWnRAw88IKvVqrVr18pkMunVV19VXl5en8f2hTXlyESD7RwLRyKqa2iLdoSp9vUEdn+gpyOMy2ntmVUvckVDe6Gb9o2pNNjOLwwunF/IROdbU25YKN+zZ48mT54su73nhiUnTpzQwoULdccdd+ipp57q89jVq1frmWee0caNG3XNNddIkiorK7Vw4UI9/PDD+ru/+7uLrodQjkyUKedYJBJRfXMw2rax2teq07Utqva1qKm15y6lDpslpnVjV0eYos6OMGYzYb2/Zcr5hfTE+YVMlJYXek6fPj1h27hx43TVVVepsrLyvMdu3bpVU6dOjQZySSorK9OsWbO0ZcuWSwrlANKXyWRSQa5DBbkOXTOuMG5fU2swenFpta9Fp2tb9PGn57TzQE/7Rqulu31jfEeY4YXZtG8EAKSFtLrQMxKJqLa2VhMnTuxzTDgc1uHDh7VkyZKEfVOmTNGOHTvk9/uVlZU1kKUCSBO52XblZts1YUx+3HZ/oL0rpLdGw/rx043648c16v6bmNlk0rCCrK4e69mdS2KKXBpRlC2HjfaNAIDUSatQ/tprr+ns2bN6/PHH+xxTX1+vYDAoj8eTsM/j8SgSicjr9Wrs2LEDWSqANJflsKpsVJ7KRsVfYxIIdXR2hInOrHeG9r1Ha6MdYUySivKc0eUvI4t7lsLQvhEAMBDS5qdLZWWlfvjDH2rGjBlatGhRn+MCgYAkxa1F7+ZwOCRJbW1tCfs+T1/rewaax5NryOfF0ME5lmj0qHzN6LUt1B7W6dpmnTrbrFM1TTp1pkmnapr09p4qhdp7OsIU5Tk1ZliuxozI1ZjhuRozLEdjhucqL8eR2jeRJji/MJA4vzCUpEUo93q9evjhh5WXl6ef/exnMpv7XuPZHbyDwWDCvu7A7nQ6L7oGLvREJuIcuzhZFpMmjMrVhFE9QSAcjsjb4I/OqHe3cPz4/ToFQh3RcTlZtq5lMPEXmebnZG77Rs4vDCTOL2SitLzQs1tTU5OWL1+upqYmvfTSS0mXpcTKz8+X3W6X1+tN2Of1emUymT73NQDgQpnNJg0vyNbwgmxNvao4uj0SiehcUyDaa73a1xna//jxWbW09bRvzHJYYm6M1LN2vSjPKXOGhnUAwMUzNJQHAgE98sgjOnHihNauXavx48d/7jFms1kTJkzQgQMHEvbt27dPpaWlXOQJYMCZTCYVup0qdDs1eXxRdHskElFjayjmpkidH/uP+fTu/tPRcXarWSO716vH3M10WEGWLOf5ayEAIDMZFso7Ojq0cuVKffTRR1q1apWmTp2adFx1dbX8fn/czYS+/OUv69lnn9WhQ4eibRGPHTum999/X8uXL09J/QCQjMlkUp7LrjyXXVeXFsTta2kLxS2Dqfa16JNT9Xr/4NnoGIvZpBGF3Xcx7VkGM7wwWzYrYR0AMpVhNw968skntX79es2dO1e33XZb3D6Xy6X58+dLkpYtW6bdu3fr8OHD0f3Nzc2688475ff79eCDD8pisWjt2rWKRCJ69dVXVVAQ/4PwQrCmHJmIc2xwaAu2R3ut9/zbopp6v7q/Q5tM0rD8rIRlMCOLsuW0GzO/wvmFgcT5hUyUlmvKKyoqJEnbt2/X9u3b4/aVlJREQ3kyOTk5+vWvf62f/OQnWrVqlcLhsGbOnKnvf//7lxTIAcBITrtVV4x064qR7rjtofYOnanzxy2DOe1r1f5jvmj7Rkkqcjujy2Bi2zi6nLZUvxUAwCUybKY83TBTjkzEOZaZ2jvC8tb7Vd19Y6Su0H7G16pgTPvGPJc9vtd6kUsji11yZ9v6pSMM5xcGEucXMlFazpQDAC6N1dJ1kWiRSzPU020qHInI19CWsAxm58HT8gd62je6nNau1o3dM+uda9cLch0Z274RANIdoRwAMoTZZJInP0ue/Cxde2XP9kgkovrmYE+f9a4WjnuOePXO3uroOIfd0hnQu2bUR3V1hCnOy5LZ3BPW3zt4Rht/X6m6xoAK3Q7ddWOZZk0akcq3CgAZh1AOABnOZDKpINehglyHJo0rjNvX2BqMhvTTXR1hDn16TjsOnImOsVnNGlHYOZve3tGhvUd9au/oXO7nawxo3ZbOa4QI5gBw6QjlADCEubPtco+1q3xs/EXyrW3tnWvVfS3RNo6VnzWotqEt4TWC7WGtf71CtfV+eQqyorP1uVn9s3YdAIYCQjkAIEG206qykjyVleTFbX/oqW1JxwdCYb3yh+Nx25x2SzSge/Kd8uRnaVjX86I8p6wW+q4DQDdCOQDgghW5HfI1BpJuf3L59aptaFNNvV/ero/a+jadqets4xiK6QxjMkmFuY6Y0N75Maxrpt3ltDLLDmBIIZQDAC7YXTeWad2WirjWi3arWXfdWCa7zdJ1YyNXwnGRSEQNLUF56/2qOdcd2tvkbfBrX6VPDS3BuPFZDos8eVlxy2E8+U4Ny89SoZtZdgCZh1AOALhg3RdzXmz3FZPJpPwch/JzHLpqdH7C/kCwQ7UN/q5Z9rboTHt1bUvXhaXxs+xFbmfi0pjoLDs3TQIw+BDKAQAXZdakEZo1aUS/3tzFYbeoxJOjEk/iTTXCkYgamnvNsjd0/vvRJ141tobixmc7rJ1hvaAnsHevZy90O2QxM8sOIP0QygEAac0c09JxwpjEWfa2YLtqu2bXe9azt6mqplkffeKNtm/sfq2iPEfcRaexH9lOfiwCMAbffQAAg5rTbtXoYTkaPSzJLHs4ovrmQEJg99b79cERr5p6zbK7nNaEi049eZ2z7YVuZ9xNlACgPxHKAQAZy2w2qdDtVKHbmdCLXZL8gfa4oN79cfJsk/Yc8aoj3DPLbjGbVJQXvxwmdnlMloMfqQAuHd9BAABDVpbDqrHDczV2eG7CvnA4orqmtoTA7q33608VTWr2x8+y52TZkvZk9+RnqSDXwSw7gPMilAMAkITZbFJxXpaK87J0dWniLHtrW3tPUG/wy9t1EeqJ00364HD8LLvVYlJRXszMel7P8pjiPCez7AAI5QAAXIpsp1WlI3JVOiJxlr0jHFZdYyBmdr3npkrHqxvV0tYeNz432xadWS+O6cnuyc9Sfq5DZm6kBGQ8QjkAAP3MYjZHl64k09IWSljLXnPOr6OfNWj3xzUKR2Jn2c0qznN2zqzHzrZ3PXfYLal6WwAGEKEcAIAUczltco2wadwId8K+9o6w6poC0eUw0dBe79cnVfXyBzrixrtd9riZ9diPvBw7s+zAIEEoBwAgjVgtZg3rulC0t0gkopbYtewxs+xHTjXo/UNnFTPJLpu1c5Y9sS+7U8X5WXLYmGUH0gWhHACAQcJkMikny6acLJuuGJl8lt3X2BYzy95zU6XDp+oVCMbPsufl2HsF9p4A73bZZWKWHUgZQjkAABnCajFreEG2hhdkJ+yLRCJq9oe6LjptjQb22nq/Kk6e03sHzihmkl12q7nXchhn3GOblVl2oD8RygEAGAJMJpNys+3KzbZr/KjEWfZQe9cse9dymNjOMR9/ek6BUPwse0GuI3q3U09B/Fp2d7aNWXbgIhHKAQCAbFazRhRma0Rh8ln2ptZQ3EWn3YH90KfndO7AmbjxDpul18x6zFr2vCzZrOY+63jv4Blt/H2l6hoDKnQ7dNeNZZo1aUS/v18g3RDKAQDAeZlMJrlddrlddpWV5CXsD7V3qLYhdpa9Zy37wRN1CobCPa8lqcDt6Grv2LUspmum/dOzTfrt20cVbO8c72sMaN2WCkkimCPjEcoBAMBlsVktGlnk0sgiV8K+SCSixpZgXFDvnnE/cNyn+ubgeV872B7Wf7x5RC6nVfk5DuXnOJSTbaPVIzIOoRwAAAwYk8mkvByH8nIcunJ04ix7INQzy/7zDfuSvkZLW7t++p89+yxmk/Jy7NGQnh/7OLfnsctpZW07Bg1COQAAMIzDZlFJsUslxS4VuR3yNQYSxuTnOLTizsmqbw6ovjnY+W9TQPXNAZ2ta9Xhk+fU0taecJzVYu4M7LkOFSQJ7d1hPstBHILxOAsBAEBauOvGMq3bUhFdUy51tmb86tyypGvZYwVDHapvCUbDejS8dwX4UzXN2n/Mp7ZevdolyWG3KD/HoYLes++5PY/zchzcbAkDilAOAADSQvfFnJfSfcVus/R5J9RY/kC7Gs4T3o9VN+pcc0ChmF8MumU7rF1BPcnSma7teS7HebvLAH0hlAMAgLQxa9IIzZo0Qh5Prrzepn5//SyHVVkOa9LWj90ikYj8gXada+od2nseHz55TvXNQXWEIwnH52TZEpbKFMSFd4fcLpssZsI7ehDKAQAAYphMJmU7bcp22lTi6XtcuOsuqfW9w3tzz0x8VU2zGlqCivTK7iZJbpc96VKZguhjOs0MJYRyAACAS2A2meTOtsudbdfY4X2PC4cjamwNJsy2dwf4c00BHT/dqMbWUMKxdJoZOgjlAAAAA8hsNkXDs86zPL69I6zGlqDO9RHez567sE4z0Rn3JBetOu0WwnuaIpQDAACkAavFrEK3U4Vu53nHBUMdnRerNgeSrHvvXDJz4FggeacZmyXh4tRkHWfoNJN6hHIAAIBBxG6zyJOfJc9ldpo5fp5OM1kOa9KlMrGz73k5dJrpT4RyAACADHRRnWZ63ZQpNsAfOVWv+uYAnWYGGKEcAABgiIrrNFPs6nNcOBJRiz+UcEfV2PD+mbdFDc1BhXu1mjlfp5memXiHcod4pxlCOQAAAM7LbDIpN9uu3Gy7xgzL6XPc5Xaa6bNNZEx4v5xOM+8dPKONv6+UrzGgoou4OVUqEMoBAADQL/qr00xNvV9HTtX30WnGFH9xatKLVh3KcsR3mnnv4Bmt21KhYNcael9jQOu2VEhSWgRzQjkAAABS6kI7zYTaO2KWyMRetNr5/LPaFh08USd/ILHTjN1mjgvv+yp90UDeLdge1sbfVxLKAQAAgL7YrBfWaaYt2K6GrvCeOPse1IkzTUlbREqdM+bpgFAOAACAQc1pt8pZaNXw83Sa+faqHUkDeJHbMZClXTD60wAAACDj3XVjmey9+qrbrWbddWOZQRXFY6YcAAAAGa973TjdVwAAAAADzZo0Im1CeG8sXwEAAAAMRigHAAAADGbo8pWamhqtX79ee/fu1YEDB9Ta2qr169dr5syZn3vsd77zHb3yyisJ26+99lr99re/HYhyAQAAgAFhaCg/fvy4Vq9erdLSUpWXl+vDDz+8qOOzsrL0gx/8IG5bYWFhf5YIAAAADDhDQ/mkSZP0/vvvq6CgQG+99ZZWrFhxUcdbrVYtWrRogKoDAAAAUsPQUJ6Tk3PZr9HR0SG/398vrwUAAAAYYVC3RGxpadGMGTPk9/uVn5+vxYsX65vf/KYcjvS4MxMAAABwIQZtKPd4PPrGN76hq6++WuFwWNu3b9fatWtVWVmpNWvWGF0eAAAAcMEGbSj/1re+Ffd8wYIFGj58uF544QXt2LFDs2fPvqjXKyoyZvmLx5NryOfF0ME5hoHE+YWBxPmFoWTQhvJkHnroIb3wwgt67733LjqUnzvXonA4MkCVJVdUlCOfrzmlnxNDC+cYBhLnFwYS5xcykdlsUkGBK+m+jArlxcXFstlsamhouOhj+/oCDTSjZugxdHCOYSBxfmEgcX5hKMmoO3qeOXNGoVCIXuUAAAAYVAZFKD958qROnjwZfR4IBNTcnPgnrVWrVkmSvvjFL6asNgAAAOByGb58pTtIV1ZWSpI2bdqkDz74QG63W0uXLpUkPfDAA5Kkbdu2SZK8Xq/uvPNOLViwQOPHj492X3nvvfd0++2367rrrkv9GwEAAAAukSkSiaT26sZeysvLk24vKSmJhvCbb75ZUk8ob2xs1I9+9CPt3btXNTU1CofDGjdunO68807dd999slgsqSkeAAAA6AeGh3IAAABgqBsUa8oBAACATEYoBwAAAAxGKAcAAAAMRigHAAAADEYoBwAAAAxmeJ/yoaampkbr16/X3r17deDAAbW2tmr9+vWaOXOm0aUhA+zbt0+vvPKKdu3aperqauXn52vatGlauXKlSktLjS4Pg9w1KXyuAAAI9klEQVT+/fv1b//2bzp06JB8Pp9yc3M1ceJErVixQtOnTze6PGSY1atX6+mnn9bEiRO1adMmo8sBBhyhPMWOHz+u1atXq7S0VOXl5frwww+NLgkZZM2aNdqzZ49uvfVWlZeXy+v16sUXX9TixYu1YcMGlZWVGV0iBrFTp06po6NDX/3qV+XxeNTU1KT/+q//0tKlS7V69WrNnj3b6BKRIbxer375y18qOzvb6FKAlKFPeYo1NzcrFAqpoKBAb731llasWMFMOfrNnj17NHnyZNnt9ui2EydOaOHChbrjjjv01FNPGVgdMpHf79f8+fM1efJkPf/880aXgwzxne98R9XV1YpEImpsbGSmHEMCa8pTLCcnRwUFBUaXgQw1ffr0uEAuSePGjdNVV12lyspKg6pCJsvKylJhYaEaGxuNLgUZYt++fXrttdf03e9+1+hSgJQilAMZLhKJqLa2ll8G0W+am5tVV1enY8eO6dlnn9WRI0c0a9Yso8tCBohEIvrRj36kxYsX6+qrrza6HCClWFMOZLjXXntNZ8+e1eOPP250KcgQ3/ve97R161ZJks1m09e+9jU98sgjBleFTPDqq6/q6NGj+sUvfmF0KUDKEcqBDFZZWakf/vCHmjFjhhYtWmR0OcgQK1as0JIlS3TmzBlt2rRJwWBQoVAoYekUcDGam5v1zDPP6K/+6q80bNgwo8sBUo7lK0CG8nq9evjhh5WXl6ef/exnMpv53x39o7y8XLNnz9Zf/uVf6oUXXtDBgwdZ/4vL9stf/lI2m00PPvig0aUAhuCnNJCBmpqatHz5cjU1NWnNmjXyeDxGl4QMZbPZNG/ePL3xxhtqa2szuhwMUjU1NVq3bp3uuece1dbWqqqqSlVVVQoEAgqFQqqqqlJDQ4PRZQIDiuUrQIYJBAJ65JFHdOLECa1du1bjx483uiRkuLa2NkUiEbW0tMjpdBpdDgYhn8+nUCikp59+Wk8//XTC/nnz5mn58uV64oknDKgOSA1COZBBOjo6tHLlSn300UdatWqVpk6danRJyCB1dXUqLCyM29bc3KytW7dq5MiRKioqMqgyDHajR49OenHnT3/6U7W2tup73/uexo0bl/rCgBQilBtg1apVkhTtG71p0yZ98MEHcrvdWrp0qZGlYZB76qmntG3bNs2dO1f19fVxN9xwuVyaP3++gdVhsFu5cqUcDoemTZsmj8ej06dPa+PGjTpz5oyeffZZo8vDIJabm5v0+9O6detksVj43oUhgTt6GqC8vDzp9pKSEm3bti3F1SCTLFu2TLt37066j/MLl2vDhg3atGmTjh49qsbGRuXm5mrq1Kl66KGH9IUvfMHo8pCBli1bxh09MWQQygEAAACD0X0FAAAAMBihHAAAADAYoRwAAAAwGKEcAAAAMBihHAAAADAYoRwAAAAwGKEcAAAAMBihHABgmGXLlunmm282ugwAMJzV6AIAAP1r165duu+++/rcb7FYdOjQoRRWBAD4PIRyAMhQCxYs0Je+9KWE7WYzfyQFgHRDKAeADHXNNddo0aJFRpcBALgATJcAwBBVVVWl8vJyPffcc9q8ebMWLlyoKVOm6KabbtJzzz2n9vb2hGMqKiq0YsUKzZw5U1OmTNHtt9+u1atXq6OjI2Gs1+vVj3/8Y82bN0+TJ0/WrFmz9OCDD2rHjh0JY8+ePatvfvObuu6663Tttdfq61//uo4fPz4g7xsA0hEz5QCQofx+v+rq6hK22+125eTkRJ9v27ZNp06d0r333qvi4mJt27ZN//qv/6rq6mr90z/9U3Tc/v37tWzZMlmt1ujY7du36+mnn1ZFRYWeeeaZ6Niqqirdfffd8vl8WrRokSZPniy/36+9e/dq586dmj17dnRsa2urli5dqmuvvVaPP/64qqqqtH79ej366KPavHmzLBbLAH2FACB9EMoBIEM999xzeu655xK233TTTXr++eejzysqKrRhwwZNmjRJkrR06VI99thj2rhxo5YsWaKpU6dKkp588kkFg0G9/PLLmjhxYnTsypUrtXnzZn3lK1/RrFmzJEk/+MEPVFNTozVr1mjOnDlxnz8cDsc9P3funL7+9a9r+fLl0W2FhYX653/+Z+3cuTPheADIRIRyAMhQS5Ys0a233pqwvbCwMO75DTfcEA3kkmQymfSNb3xDb731lt58801NnTpVPp9PH374oW655ZZoIO8e+9d//dd6/fXX9eabb2rWrFmqr6/XH/7wB82ZMydpoO59oanZbE7oFnP99ddLkj799FNCOYAhgVAOABmqtLRUN9xww+eOKysrS9h25ZVXSpJOnTolqXM5Suz2WOPHj5fZbI6OPXnypCKRiK655poLqnPYsGFyOBxx2/Lz8yVJ9fX1F/QaADDYcaEnAMBQ51szHolEUlgJABiHUA4AQ1xlZWXCtqNHj0qSxowZI0kaPXp03PZYx44dUzgcjo4dO3asTCaTPv7444EqGQAyDqEcAIa4nTt36uDBg9HnkUhEa9askSTNnz9fklRUVKRp06Zp+/btOnLkSNzYX/3qV5KkW265RVLn0pMvfelLeuedd7Rz586Ez8fsNwAkYk05AGSoQ4cOadOmTUn3dYdtSZo4caLuv/9+3XvvvfJ4PHr77be1c+dOLVq0SNOmTYuO+/73v69ly5bp3nvv1T333COPx6Pt27fr3Xff1YIFC6KdVyTpH//xH3Xo0CEtX75cixcv1qRJkxQIBLR3716VlJTo29/+9sC9cQAYhAjlAJChNm/erM2bNyfd98Ybb0TXct9888264oor9Pzzz+v48eMqKirSo48+qkcffTTumClTpujll1/Wz3/+c7300ktqbW3VmDFj9MQTT+ihhx6KGztmzBj97ne/0y9+8Qu988472rRpk9xutyZOnKglS5YMzBsGgEHMFOHviAAwJFVVVWnevHl67LHH9Dd/8zdGlwMAQxprygEAAACDEcoBAAAAgxHKAQAAAIOxphwAAAAwGDPlAAAAgMEI5QAAAIDBCOUAAACAwQjlAAAAgMEI5QAAAIDBCOUAAACAwf4/Yie/VM4qEfUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfjYoa6WmkN6"
      },
      "source": [
        "# Display Model Info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PIiVlDYCtSq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "dbcd8b9c-6411-42c9-958c-db96ed008ad3"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The GPT-2 model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:2]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[2:14]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-2:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The GPT-2 model has 148 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "transformer.wte.weight                                  (50259, 768)\n",
            "transformer.wpe.weight                                   (1024, 768)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "transformer.h.0.ln_1.weight                                   (768,)\n",
            "transformer.h.0.ln_1.bias                                     (768,)\n",
            "transformer.h.0.attn.c_attn.weight                       (768, 2304)\n",
            "transformer.h.0.attn.c_attn.bias                             (2304,)\n",
            "transformer.h.0.attn.c_proj.weight                        (768, 768)\n",
            "transformer.h.0.attn.c_proj.bias                              (768,)\n",
            "transformer.h.0.ln_2.weight                                   (768,)\n",
            "transformer.h.0.ln_2.bias                                     (768,)\n",
            "transformer.h.0.mlp.c_fc.weight                          (768, 3072)\n",
            "transformer.h.0.mlp.c_fc.bias                                (3072,)\n",
            "transformer.h.0.mlp.c_proj.weight                        (3072, 768)\n",
            "transformer.h.0.mlp.c_proj.bias                               (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "transformer.ln_f.weight                                       (768,)\n",
            "transformer.ln_f.bias                                         (768,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2079Qyn8Mt8"
      },
      "source": [
        "# Saving & Loading Fine-Tuned Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ulTWaOr8QNY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "0aa1c212-f566-4526-d83e-25647b32de68"
      },
      "source": [
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./model_save/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/vocab.json',\n",
              " './model_save/merges.txt',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqMzI3VTCZo5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "ef38ff34-c13c-4c76-ec76-f1b5973c9304"
      },
      "source": [
        "!ls -l --block-size=K ./model_save/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 499796K\n",
            "-rw-r--r-- 1 root root      1K Aug 27 13:16 added_tokens.json\n",
            "-rw-r--r-- 1 root root      1K Aug 27 13:16 config.json\n",
            "-rw-r--r-- 1 root root    446K Aug 27 13:16 merges.txt\n",
            "-rw-r--r-- 1 root root 498451K Aug 27 13:16 pytorch_model.bin\n",
            "-rw-r--r-- 1 root root      1K Aug 27 13:16 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root      1K Aug 27 13:16 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root    878K Aug 27 13:16 vocab.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WUFUIQ8Cu8D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0fadb954-c8de-4b40-8c1d-2b6d6231d8d5"
      },
      "source": [
        "!ls -l --block-size=M ./model_save/pytorch_model.bin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 487M Aug 27 13:16 ./model_save/pytorch_model.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxlZsafTC-V5"
      },
      "source": [
        "# Copy the model files to a directory in your Google Drive.\n",
        "!cp -r ./model_save/ $data_dir\n",
        "\n",
        "# # Load a trained model and vocabulary that you have fine-tuned\n",
        "#model = GPT2LMHeadModel.from_pretrained(output_dir)\n",
        "#tokenizer = GPT2Tokenizer.from_pretrained(output_dir)\n",
        "#model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLf6rbRglYhQ"
      },
      "source": [
        "# Generate Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4XhewaV93-_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "8084aae0-dd9b-4556-a451-393e44e10aef"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "prompt = \"<|startoftext|>\"\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "print(generated)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                #bos_token_id=random.randint(1,30000),\n",
        "                                do_sample=True,   \n",
        "                                top_k=50, \n",
        "                                max_length = 300,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=3\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([[50258]], device='cuda:0')\n",
            "0: One of the world’s most beloved techno artists, Simko began DJing around 1980 at the age of 13 in Warsaw.\n",
            "\n",
            "One of the early innovators in the techno scene, Simko was able to gain invaluable experience at the highest level. His sets, widely known as his \"Brock Theme\" or “Brock S”, were released in the infamous magazine magazines, Ultraschall and later, Freakout Magazine, followed by gigs in New York, Los Angeles and Berlin.\n",
            "\n",
            "Following several highly successful releases, Simko began a career as a member of the renowned Electronic Techno trio. Their early releases “Lapis Amnesia” and “Nakase” established Simko as a vital component in their long and illustrious career.\n",
            "\n",
            "Over two decades later Simko continues to produce and release material that continues to captivate the music and the dancefloor. From his seminal “Blank Space” and “Rube Geis” series, to his recent work on The End Of All Existence “The End Of All Existence”, he continues to deliver in uncompromising style.\n",
            "\n",
            "Simko’s contribution to the European techno scene was heavily supported, most notably by DJ Mag, who ranked him one of the Top DJs in the world. He was also selected by DJ Mag and Mixmag as one of the Best European DJs of 2007.\n",
            "\n",
            "As\n",
            "\n",
            "\n",
            "1: It started off as a mere project that would involve a bunch of guys from the Czech Republic and Germany. But the following year, in 2015 the project progressed into a more serious endeavor. That was the project that brought Marcel Dettmann together with Daniel Orphara, Daniel Pantaleon, and Sebastian Thorne. As a reaction to Pantaleon's decision to close the project, Marcel Dettmann began to search for music to make the project sustainable, and in 2016 he decided to begin a new project. Called The Rave Recordings Company, or simply The Rave Recordings Organization, it’s a collective of musicians working together to create beats for some of the most influential electronic music on the planet.\n",
            "\n",
            "At first Marcel Dettmann was somewhat unknown to everyone but to his fans, who were heavily inspired by the artist. He started producing with his friend and sound engineer, Joris Voorn, under the alias “The Rave Radio Project” in 2017. Since then the project has evolved into the more serious project of the project known as The Rave Exchange, a new label formed on the principles of collaboration and sharing the knowledge, creativity, and ideas of artists. Currently The Rave Exchange is composed of all the residents of Berlin, with whom Marcel Dettmann has a deep connection. The Rave Exchange’s goal is to provide a platform for artists in various fields, from the clubbing to the film and theatre industry.\n",
            "\n",
            "\n",
            "2: A staple of the London club scene since its founding in 1991, Krivit grew up in suburban London. In the mid-nineties he was a key part of a crew of DJs in the infamous Deep House club called Watergate. In the autumn of 2004 he moved to Berlin. Around this time he formed Tresor and quickly became one of its most important and sought after DJs. Throughout his earlier years, Krivit was also active in localised fashion agencies and his monthly show 'Krivit' was a regular feature in various local parties and boutiques. During this period, he played a vast range of electronic music at iconic venues and boutiques including Berghain, Pacha, Fabric, Robert Johnson, Rex, Soho and many more.\n",
            "\n",
            "In 2007 he was elected as resident DJ of the Berghain club in London. In the same year he started his own event series 'Krivit' in the Hamptons, an extension of the now legendary Ostgut Ton club. During this period Krivit gained the respect of the London club establishment and as such gained the reputation of becoming one of the most highly regarded DJs in the world. From his popularity and reputation he created 'Krivit 2.0' label and it was this that Krivit set about producing his own unique style and which has gained him worldwide recognition for his unique approach to DJing. During this period he also became one of the best known European DJ at\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4LrX5H-0nAU"
      },
      "source": [
        "These aren't bad at all!\n"
      ]
    }
  ]
}